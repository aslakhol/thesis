== Related Work
// === Eye Tracking and Cognitive Performance

// Eye-tracking uses devices and software to track and record the position of a subject's eyes while interacting with digital devices. Eye-tracking can be used for input control or recording behavior during interactions with a system.

// As the technology has improved and systems become cheaper and cheaper, eye-tracking has emerged as an effective, efficient, and cheap non-invasive method of tracking attention and cognitive workload and many other factors.

// There are several different ways of performing eye-tracking. We are working with optical eye-trackers, which point the camera to the subject and record their pupils' position. The imagery is interpreted by software, and the eyes' positions are extracted, as well as any blinks and the pupillary response, how much the pupils dilate and trick. This information is recorded in the form of a time series of the x and y position of where each subject's eyes are looking.

// From this data, we can extract several features. The position of one's gaze on the page could itself be a valuable point of information, usually referred to as areas of interest.

// Pupil dilation in and of itself has been shown to have direct relationships with how one processes data presented one is presented with. As such pupillary response over time is a promising feature. Blinking can, in the same way, give us some indication of how one is processing information.

// A fixation in attracting is when your gaze rests on a particular point for a certain amount of time fixation would usually indicate a higher level of attention to that specific region of the screen.

// Saccades are the rapid eye movement between two fixations. Information is not processed during a saccade. However, we can still learn something about how one processes information and the information being processed. For example, one would see a higher degree of saccades for texts that consist of longer and more complicated words.

// The duration of the saccades and fixations, the lengths of saccades, and the relationship between saccades and fixations in the dataset can give us insight into how the subject processes information.

// The features we are engineering in this thesis are primarily higher-order features built on top of the lower order features that we have just mentioned.

// asciimath::[1_1]

=== Eye Tracking and Cognitive Performance

Since gaze data of a human can be associated with cognition citenp:[raptisUsingEyeTracking2016], multiple studies have been conducted to find relationships between eye-tracking and cognitive performance.
As cognitive load can be a proxy between a task and a subject's performance, citenp:[haapalainenferreiraPsychoPhysiologicalMeasuresAssessing2010], literature concerning gaze data and cognitive load is highly relevant for this thesis.
Zhang et al. citenp:[zhangTuC4DriverCognitive] classified a driver's cognitive load in two classes, using the direction of the subject's gaze and the mean and standard deviation of pupil diameter changes.
They achieved significant results using a decision tree classifier.
Haapalainen et al. citenp:[haapalainenferreiraPsychoPhysiologicalMeasuresAssessing2010] used multiple physiological sensors and combinations of their signals to determine their usefulness.
Their results show that the pupillometry was one of the least valuable features for their problem.
However, Steichen et al. citenp:[steichenUseradaptiveInformationVisualization2013] investigated how to infer cognitive abilities from gaze data and showed that using aggregated features from gaze-data can predict a subject's perceptual speed and visual working memory reliably.
Toker et al. citenp:[tokerPupillometryHeadDistance2017] has also shown that including pupil dilation to the same feature set as Steichen has a significant effect on predictions of confusion and skill acquisition.
Chen and Epps citenp:[chenUsingTaskInducedPupil2014] did binary classification on cognitive load using a Gaussian mixture model with pupil dilation and blink frequency.
Their work showed promising results for the automatic prediction of cognitive load with gaze data.


There are also novel features engineered from gaze data.
Duchowski et al. citenp:[duchowskiIndexPupillaryActivity2018] engineered a measure of the frequency of pupil diameter oscillation which captures an indicator of cognitive load, called Index of Pupillary activity (IPA).
IPA was proposed as an alternative to the existing Index of Cognitive Activity (ICA) since ICA is not available to the public.
Later they proposed an improvement to IPA called The Low High Index of pupillary activity citenp:[duchowskiLowHighIndex2020], which can discriminate cognitive load in several experiments where IPA fails do so.
Sharma et al. citenp:[sharmaEyetrackingArtificialIntelligence2020] used heatmaps generated from the fixtures of subjects to predict students' performance.
Features from the heatmaps were extracted with a pre-trained VGG19 model.
They showed that cognitive performance could be predicted with an error rate of less than 5%.


Even though gaze-data has shown promising results in predicting cognitive workload and performance, there is little work in the literature that addresses inferring cognitive performance between contexts from gaze data.















LHIPA citenp:[duchowskiLowHighIndex2020]

=== Feature Generalizability
