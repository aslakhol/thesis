== Related Work
// === Eye Tracking and Cognitive Performance

// Eye-tracking uses devices and software to track and record the position of a subject's eyes while interacting with digital devices. Eye-tracking can be used for input control or recording behavior during interactions with a system.

// As the technology has improved and systems become cheaper and cheaper, eye-tracking has emerged as an effective, efficient, and cheap non-invasive method of tracking attention and cognitive workload and many other factors.

// There are several different ways of performing eye-tracking. We are working with optical eye-trackers, which point the camera to the subject and record their pupils' position. The imagery is interpreted by software, and the eyes' positions are extracted, as well as any blinks and the pupillary response, how much the pupils dilate and trick. This information is recorded in the form of a time series of the x and y position of where each subject's eyes are looking.

// From this data, we can extract several features. The position of one's gaze on the page could itself be a valuable point of information, usually referred to as areas of interest.

// Pupil dilation in and of itself has been shown to have direct relationships with how one processes data presented one is presented with. As such pupillary response over time is a promising feature. Blinking can, in the same way, give us some indication of how one is processing information.

// A fixation in attracting is when your gaze rests on a particular point for a certain amount of time fixation would usually indicate a higher level of attention to that specific region of the screen.

// Saccades are the rapid eye movement between two fixations. Information is not processed during a saccade. However, we can still learn something about how one processes information and the information being processed. For example, one would see a higher degree of saccades for texts that consist of longer and more complicated words.

// The duration of the saccades and fixations, the lengths of saccades, and the relationship between saccades and fixations in the dataset can give us insight into how the subject processes information.

// The features we are engineering in this thesis are primarily higher-order features built on top of the lower order features that we have just mentioned.

// asciimath::[1_1]

=== Eye Tracking and Cognitive Performance

Since gaze data of a human can be associated with cognition citenp:[raptisUsingEyeTracking2016], multiple studies have been conducted to find relationships between eye-tracking and cognitive performance.
As cognitive load can be a proxy between a task and a subject's performance, citenp:[haapalainenferreiraPsychoPhysiologicalMeasuresAssessing2010], literature concerning gaze data and cognitive load is highly relevant for this thesis.
Zhang et al. citenp:[zhangTuC4DriverCognitive] classified a driver's cognitive load in two classes, using the direction of the subject's gaze and the mean and standard deviation of pupil diameter changes.
They achieved significant results using a decision tree classifier.
Haapalainen et al. citenp:[haapalainenferreiraPsychoPhysiologicalMeasuresAssessing2010] used multiple physiological sensors and combinations of their signals to determine their usefulness.
Their results show that the pupillometry was one of the least valuable features for their problem.
However, Steichen et al. citenp:[steichenUseradaptiveInformationVisualization2013] investigated how to infer cognitive abilities from gaze data and showed aggregated features from gaze data could predict a subject's perceptual speed and visual working memory reliably.
Toker et al. citenp:[tokerPupillometryHeadDistance2017] has also shown that including pupil dilation to the same feature set as Steichen has a significant effect on predictions of confusion and skill acquisition.
Chen and Epps citenp:[chenUsingTaskInducedPupil2014] did binary classification on cognitive load using a Gaussian mixture model with pupil dilation and blink frequency.
Their work showed promising results for the automatic prediction of cognitive load with gaze data.


There are also novel features engineered from gaze data.
Duchowski et al. citenp:[duchowskiIndexPupillaryActivity2018] engineered a measure of the frequency of pupil diameter oscillation which captures an indicator of cognitive load, called Index of Pupillary activity (IPA).
IPA was proposed as an alternative to the existing Index of Cognitive Activity (ICA) since ICA is not available to the public.
Later they proposed an improvement to IPA called The Low High Index of pupillary activity citenp:[duchowskiLowHighIndex2020], which can discriminate cognitive load in several experiments where IPA fails do so.
Sharma et al. citenp:[sharmaEyetrackingArtificialIntelligence2020] used heatmaps generated from the fixtures of subjects to predict students' performance.
Features from the heatmaps were extracted with a pre-trained VGG19 model.
They showed that cognitive performance could be predicted with an error rate of less than 5%.


Even though gaze-data has shown promising results in predicting cognitive workload and performance, there is little work in the literature that addresses inferring cognitive performance between contexts from gaze data.


=== Generalizability
While universalism and context sensitivity in information systems research remain an essential topic of research, citenp:[davisonContextKingConsidering2016, chengContextMayBe2016] generalizability continues to be a chief concern in machine learning research.
It is named as one of the primary goals in a slew of fields ranging from healthcare analytics citenp:[dexterGeneralizationMachineLearning2020, MachineLearningArtificial], business research citenp:[salminenMachineLearningApproach2019], finance citenp:[mcnallyPredictingPriceBitcoin2018] to psychiatry citenp:[chekroudCrosstrialPredictionTreatment2016]

Turney has worked to provide a formal definition of context sensitive features within concept learning citenp:[turneyIdentificationContextSensitiveFeatures2002, turneyExploitingContextWhen1993, turneyRobustClassificationContextsensitive1993].
His work is strengthened by John et al. citenp:[johnIrrelevantFeaturesSubset1994] and others.
While our view of context is tangential to his, the definition of context-sensitive features as features that are relevant only given a set context is still applicable to our work.
We look to engineer generalizable features that provide predictive power on data gathered outside of the context that the feature was generated in.

Bouchard et al. works with technologies for ambient intelligence aiming to increase the autonomy of elderly through enhanced tracking to assist medical personel.
From on their work with bluetooth beacons they present a feature based on the received signal strength indication timeseries that generalizes between contexts made up of different hardware, different hardware configurations and different floor plans citenp:[bouchardGeneralizableSpatialFeature2016].

Ferentzi et al. investigated whether information gained from a single interoceptive modality (mode of understanding ones own body) can be generalized to other modalities. citenp:[ferentziMultichannelInvestigationInteroception2018]
They investigated a group of students ability to count their own heartbeats, sense their gastric fullness, sense bitterness, their pain threshold, proprioceptive sensitivity (ability to position their limbs) and their sense of balance.
The correlations of each of the experiments were estimated used Spearman correlation citenp:[wisslerSpearmanCorrelationFormula1905].
They argue that their findings strongly support that interoceptive accuracy assessed with a single modality cannot be generalized to other modalities.

Feature generalizability has seen some popularity in Brain Computer Interfaces (BCI) research. Wang et al. demonstrates generalizable features generated by using a simple deep neural network to decode learning strategies from electroencaphalography (EEG) EEG signals gathered when subjects execute a learning strategy task that included context switching.
Nurse et al. also showed an approach including a high-dimension neural network that was used to do real-time classification of EEG for use in BCI.
In this approach a neural network acted as both feature extractor and classifier and the technique was shown to generalize citenp:[nurseGeneralizableBrainComputerInterface2015].

Recently feature generalizability has also been shown to have relevance when predicting driver's intentions at intersections in an automotive context citenp:[phillipsGeneralizableIntentionPrediction2017], when using ML for personality assessment citenp:[bleidornUsingMachineLearning2019], in speech enhancement systems citenp:[babyBiophysicallyinspiredFeaturesImprove2018], in face-based attention mind wandering detection citenp:[stewartGeneralizabilityFaceBasedMind], and in music information retrieval citenp:[saariGeneralizabilitySimplicityCriteria2011].


LHIPA citenp:[duchowskiLowHighIndex2020]

=== Feature Generalizability
