[[introduction]]
== Introduction

=== Motivation

==== Cognition
The evaluation of cognition or cognitive performance is essential for a variety of fields.
Cognition describes the different workings of our mental capacities.
Weintraub et al. citenp:[weintraubCognitionAssessmentUsing2013] identified executive function, episodic memory, language, processing speed, working memory as the most critical cognition subdomains for health, success in school and work, and independence in daily functioning.
The NIH Toolbox Cognition Batteries is a well-established set of tests of cognition citenp:[weintraubCognitionAssessmentUsing2013].
While the tests in the NIH Toolbox are thorough and well tested, they are also quite involved and take much time to perform.
We need a proxy if we are to evaluate cognitive performance in a micro context.

Cognitive workload describes the level of mental resources that one person requires to perform a task and naturally falls within the purview of cognitive performance.
The perceived workload can be affected by many different factors such as the complexity of the task, the task's size, and external factors like how well one slept that night.
Cognitive workload has also been shown to influence one's eye movements. citenp:[shojaeizadehDetectingTaskDemand2019, LowHighIndex, duchowskiIndexPupillaryActivity2018].

Our project will include data gathered from studies handling many different cognitive tasks.
We will argue that each task has some measure, such as a score, that correlates to the cognitive performance for that task.

==== Eye-tracking

Eye-tracking is the process of tracking and recording the position of a subject's eyes while interacting with digital devices.
The gaze point for each of the eyes of a subject is recorded over time.
Eye-tracking can be used as input control for interacting with systems citenp:[cantoniEyeTrackingComputer2014], or to record user behavior when interacting with digital and physical systems citenp:[grankaEyeTrackingAnalysisUser2004, bojkoEyeTrackingUser2005].
As the equipment involved has become cheaper and more readily available, eye-tracking has emerged as a promising non-invasive way to evaluate many facets of interactions with digital systems.
These include collaborative work in MOOC learners citenp:[sharmaLookingLookingDual2015], colaboration when interacting with Intelligent Tutoring Systems citenp:[sharmaMeasuringCausalityCollaborative2021], detecting task-demand citenp:[shojaeizadehDetectingTaskDemand2019, duchowskiIndexPupillaryActivity2018].

==== Generalizability

Universality and generalism of research are important concepts, and their role in information systems research is an ongoing debate citenp:[davisonContextKingConsidering2016, chengContextMayBe2016].
Davison et al. point out that one must be explicitly aware of the context of one's research and avoid unjustified generalization citenp:[davisonContextKingConsidering2016].
Cheng et al. agree that a close look at the context of a study is critical.
However, they underline that generalizability is the ultimate goal of research, and well-reasoned generalizability should be pursued citenp:[chengContextMayBe2016].
Our work is acutely aware of the context of each of the datasets we use, and we will aim to engineer features that are generalizable to other contexts.
We will evaluate the degree of generalizability of each of the pipelines used to produce our results through statistical analysis.

While generalizability is an oft pursued goal in machine learning, there is little focus on feature generalizability in the literature.
Inspired by the methods of Sharma et al. citenp:[sharmaAssessingCognitivePerformance2020], we aim to engineer features that are produced with data from one or more specific contexts and can be used to predict the same variables on datasets gathered in other contexts.
The usefulness of understanding the rationale behind features and how they might differ when predicting the same target on different types of data has been studied by Rogers et al. in the context of text mining citenp:[rogersGeneralizabilityDocumentFeatures2017].
Feature generalizability has also been considered a central goal in feature selection within music information retrieval citenp:[saariGeneralizabilitySimplicityCriteria2011].
It has also been shown to be important in predicting students' affect during learning citenp:[huttTimeScaleGeneralizable2019].

Sharma et al. engineered generalizable features from physiological data and facial expressions.
They evaluated their features with a proposed "feature generalizability index" metric. citenp:[sharmaAssessingCognitivePerformance2020].
We will follow their methodology to develop generalizable features from gaze data.
In addition, we will present a machine learning platform we have developed to effectively run experiments to investigate generalizability and produce features from eye-tracking data.

=== Research Questions
This study aims to create a system that can perform feature generalizability experiments on gaze data.
To determine which features and which methods for reducing the feature space are generalizable.
From this, we can extract the following research questions.

- *RQ 1* What are the most generalizable features for predicting cognitive performance using gaze data?
- *RQ 1 a* What are the most context-specific features for predicting cognitive performance using gaze data?

=== Terminology

In this section, we will introduce the reader to a few key terms from the eye-tracking world.

The term fixation refers to when the eye holds steady on an object or a position.
In a fixation, recorded gaze points vary little in both time and space.
Fixations usually reflect attention to a stimulus citenp:[shojaeizadehDetectingTaskDemand2019].
When discussing fixations, we will often refer to the fixation duration, which is the amount between the start of the fixation and the end of the fixation

Saccades are small rapid eye movements that occur between two fixations.
It is moving the eye from one stimulus to another.
Cognitive information is not processed during saccadic eye movements.
However, studies have shown that they still can provide information about viewing behavior and indicate changes in cognition citenp:[shojaeizadehDetectingTaskDemand2019].
We will primarily refer to the measures saccade duration and saccade length.
Saccade length is the euclidian distance between the two fixations.
Saccade duration is the time that the eye movements take, the time between the two fixations.

Pupillary changes are changes in pupil size.
We will most commonly refer to pupil diameter, which is the size in pixels or millimeters that the pupil has at a point in time.
Changes to the pupil diameter can serve as a reliable proxy of mental effort citenp:[shojaeizadehDetectingTaskDemand2019].

=== Outline

[discrete]
===== xref:introduction[]: Introduction

Our introduction introduces the motivation for the work, our research questions, some key terminology, and this outline.

[discrete]
===== xref:related_work[]: Related work

The related work chapter situates our work in relation to the established literature and provides the theoretical background that outlines our assumptions.

[discrete]
===== xref:study[]: Study

This chapter outlines how we approach engineering generalizable features from gaze data and presents the datasets used in our experiments.

[discrete]
===== xref:implementation[]: Implementation

Our chapter on implementation presents the requirements for our platform, describes the architecture we propose to meet these requirements, and presents details on how we implement that architecture, including how and which features we engineer and how we evaluate our pipelines.

[discrete]
===== xref:results[]: Results

This chapter presents a range of tables and plots representing the evaluations of our pipelines and provides assistance in interpreting the presented materials.

[discrete]
===== xref:discussion[]: Discussion

The discussion delves further into the results, presents our thoughts on the patterns displayed by the results, and discusses the results in relation to the literature.

[discrete]
===== xref:conclusion[]: Conclusion

At last, the conclusion presents a summary of the work, the contributions of the work, and suggestions for further work.
