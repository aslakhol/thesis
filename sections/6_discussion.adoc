[[discussion]]
== Discussion

=== Findings
- 2-to-1 pipelines are more generalizable than 1-to-1 pipelines.
- 2-to-1 pipelines where Fractions and CSCW are the in-study datasets produce more generalizable pipelines.
- GARCH, Power Spectral Histogram, heatmaps, saccade duration, saccade length, and Markov can produce generalizable pipelines.
- Pupil Diameter, Eye tracking, LHIPA, and ARMA can produce context-sensitive pipelines, and we do not observe any tendencies to generalize.

=== Filtering on baseline
Our goal is to identify generalizable pipelines, and for that, we have the FGI measure.
FGI describes how similar the distribution of errors from *out-of-sample* testing and *out-of-study* testing and is a measure of generalizability.
However, it is not enough that the two distributions are similar.
Generalizability should be a measure of usable predictive power in outside contexts.
Random guesses would create identical distributions of error in *out-of-sample* testing and *out-of-study* testing, and as such, would have a good FGI value.
To counteract this, we chose to disregard all pipelines that do not outperform their respective baselines for the purpose of measuring generalizability.
We do this by filtering the set of completed baselines.

=== 2-to-1 versus 1-to-1
As shown in xref:distribution_fgi[] 2-to-1 pipelines tend to generalize better then 1-to-1 pipelines.
Combining two datasets from two separate contexts for training introduces more variance.
Unsurprisingly, these pipelines are more generalizable than those that use only one dataset for training.
These results align with the findings of Sharma et al. citenp:[sharmaAssessingCognitivePerformance2020].
In further discussions, we will focus on results from the 2-to-1 pipelines.


=== Generalizability of our datasets
Our results indicate that pipelines that combine Fractions and CSCW for training and use EMIP for testing are more generalizable than pipelines where EMIP is included in the training set.
The EMIP dataset consists of gaze data recorded of people completing individual tasks.
All datasets include information from one or more context-specific tasks, but the Fractions and CSCW also have a collaborative aspect.
We theorize that pipelines trained on EMIP do worse at describing this collaborative aspect and that the variance introduced by the interactions that come with collaborative work assists those pipelines in generalizing.
Pinpointing the effectiveness of training on collaborative data when generalizing to contexts without a collaborative aspect is a promising area for more experimentation.


=== Why do the generalizable features generalize?
In this section, we will argue a few reasons we believe as to why the features generalize.


==== Heatmaps
We observe that heatmaps are among the generalizable features.
Our heatmap feature is the gaze-position for each subject over time, split into 30 partitions, converted to a heatmap, and fed to a pre-trained VGG19 model.
The resulting feature vector is the feature we call heatmaps.
While the stimulus is not included in the heatmap image, the stimulus is captured through the subject's interaction with it, as the gaze pattern will follow the stimulus.
The feature vector we call heatmaps represents how the gaze interacts with the given stimuli. Taking EMIP as an example, a heatmap will tell us the shape of the code being presented to the subject for all subjects.
However,  it will also tell us how much time a subject spends reading the syntactic structures versus the variable names or conditional logic.
The latter is a focus point for experienced coders.
Heatmaps generalize well because instead of just capturing how a subject interacts with their stimulus, it also captures their interaction patterns and how they relate to their presented stimuli.
In addition, heatmaps encode information about time and space, rather than just one of the dimensions, introducing more variance.


==== GARCH, Hidden Markov Models and Power Spectral Histogram
GARCH is a statistical modeling technique used to model timeseries data.
Our data suggest that GARCH is the most generalizable feature group of the ones we have tested.
GARCH is models the variance of data and has the heteroscedasticity property.
Heteroscedasticity means that the random disturbance is different across the elements.
In our case, this means the variance of indicators of cognitive performance varies from point to point in the timeseries.
In different contexts, the timing of the indicators will vary based on the task and other factors.
This might explain why GARCH is generalizable across contexts.

Our results indicate that spectral histograms generalize pretty well.
Spectral histograms are the distribution of frequencies and their corresponding amplitudes.
Spectral histograms capture repetitiveness and hence might capture patterns of behavior exhibited by the subjects.
Repetitiveness indicates a flow which suggests that the subject is comfortable in their task as opposed to more chaotic non-repetitive behavior that might occur when one is not comfortable.
We suggest that this relationship should be represented across contexts and could be a reason why spectral histograms seem to generalize quite well.

We do not know why HMM generalizes this is a mystery, and a subject for future discussions with Sharma et al. citenp:[sharmaAssessingCognitivePerformance2020, sharmaEyetrackingArtificialIntelligence2020, sharmaLookingLookingDual2015, sharmaMeasuringCausalityCollaborative2021]

==== Saccade duration and Saccade length

Both saccade duration and saccade length seem to generalize.
To repeat, saccades are the movements of the eyes from one fixation to another.
As one example, both lower saccade durations and longer saccade lengths might indicate familiarity with the stimulus.
As discussed in xref:skewness_saccade_speed[] higher saccade speeds correlate with familiarity with the stimulus citenp:[pappasVisualAestheticsECommerce2018].
Saccade speed is a function of saccade duration and saccade length both factors map familiarity in some degree.
Since familiarity with the interface would be relevant in all tasks that our datasets contain this might be a reason why saccade duration and saccade length generalize.
De Luca et al. citenp:[delucaReadingWordsPseudowords2002] show that saccadic length increases when reading longer pseudowords.
Indicating that saccadic length correlates with perceived task difficulity.
Perceived task difficulity, or increased cognitive workload will correlate to cognitive performance across contexts.



2.2.2. Saccade
Saccades refer to small, rapid eye movements when jumping from fixating on one object to another [31]. While visual information is not processed during saccadic eye movements [20], they still can provide information about viewing behavior [38,41]. For example, people tend to exhibit more saccadic eye movements when reading long pseudo- words [19]. Similarly, saccade amplitude, or the path traveled by a saccade between two consecutive fixations, tends to increase when reading longer words [19]. When interacting with an online resource, longer saccadic amplitudes can reflect whether users have become

familiar with an interface. Having a better internal representation of an interface allows users to move their eyes directly to a desired location on the screen, hence producing longer saccadic amplitudes [31]. Con- sistent with this point of view, difficulty in locating information when browsing a webpage is likely to impact the duration of saccades. Ac- cording to the theory of visual hierarchy [29], a stimulus is inspected by scanning it through a sequence of visual entry points. Each entry point acts like an anchor, which allows the user to scan for information around it. According to this perspective, longer duration of saccadic eye movements could indicate increased cognitive effort in finding a sui- table entry point into a visual display [20].







=== Limitations
