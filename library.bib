
@inproceedings{babyBiophysicallyinspiredFeaturesImprove2018,
  title = {Biophysically-Inspired {{Features Improve}} the {{Generalizability}} of {{Neural Network}}-Based {{Speech Enhancement Systems}}},
  booktitle = {Interspeech 2018},
  author = {Baby, Deepak and Verhulst, Sarah},
  year = {2018},
  month = sep,
  pages = {3264--3268},
  publisher = {{ISCA}},
  doi = {10.21437/Interspeech.2018-1237},
  abstract = {Recent advances in neural network (NN)-based speech enhancement schemes are shown to outperform most conventional techniques. However, the performance of such systems in adverse listening conditions such as negative signal-to-noise ratios and unseen noises is still far from that of humans. Motivated by the remarkable performance of humans under these challenging conditions, this paper investigates whether biophysicallyinspired features can mitigate the poor generalization capabilities of NN-based speech enhancement systems. We make use of features derived from several human auditory periphery models for training a speech enhancement system that employs long short-term memory (LSTM), and evaluate them on a variety of mismatched testing conditions. The results reveal that biophysically-inspired auditory models such as nonlinear transmission line models improve the generalizability of LSTMbased noise suppression systems in terms of various objective quality measures, suggesting that such features lead to robust speech representations that are less sensitive to the noise type.},
  file = {/Users/august/Zotero/storage/8CT69J7X/Baby and Verhulst - 2018 - Biophysically-inspired Features Improve the Genera.pdf},
  language = {en}
}

@article{bednarikEMIPEyeMovements2020,
  title = {{{EMIP}}: {{The}} Eye Movements in Programming Dataset},
  shorttitle = {{{EMIP}}},
  author = {Bednarik, Roman and Busjahn, Teresa and Gibaldi, Agostino and Ahadi, Alireza and Bielikova, Maria and Crosby, Martha and Essig, Kai and Fagerholm, Fabian and Jbara, Ahmad and Lister, Raymond and Orlov, Pavel and Paterson, James and Sharif, Bonita and Sirki{\"a}, Teemu and Stelovsky, Jan and Tvarozek, Jozef and Vrzakova, Hana and {van der Linde}, Ian},
  year = {2020},
  month = oct,
  volume = {198},
  pages = {102520},
  issn = {0167-6423},
  doi = {10.1016/j.scico.2020.102520},
  abstract = {A large dataset that contains the eye movements of N=216 programmers of different experience levels captured during two code comprehension tasks is presented. Data are grouped in terms of programming expertise (from none to high) and other demographic descriptors. Data were collected through an international collaborative effort that involved eleven research teams across eight countries on four continents. The same eye tracking apparatus and software was used for the data collection. The Eye Movements in Programming (EMIP) dataset is freely available for download. The varied metadata in the EMIP dataset provides fertile ground for the analysis of gaze behavior and may be used to make novel insights about code comprehension.},
  file = {/Users/august/Zotero/storage/ECVX59TH/Bednarik et al. - 2020 - EMIP The eye movements in programming dataset.pdf;/Users/august/Zotero/storage/W2YVK52Q/S0167642320301283.html},
  journal = {Science of Computer Programming},
  keywords = {Dataset,Eye-tracking,Program comprehension},
  language = {en}
}

@article{bleidornUsingMachineLearning2019,
  title = {Using {{Machine Learning}} to {{Advance Personality Assessment}} and {{Theory}}},
  author = {Bleidorn, Wiebke and Hopwood, Christopher James},
  year = {2019},
  month = may,
  volume = {23},
  pages = {190--203},
  publisher = {{SAGE Publications Inc}},
  issn = {1088-8683},
  doi = {10.1177/1088868318772990},
  abstract = {Machine learning has led to important advances in society. One of the most exciting applications of machine learning in psychological science has been the development of assessment tools that can powerfully predict human behavior and personality traits. Thus far, machine learning approaches to personality assessment have focused on the associations between social media and other digital records with established personality measures. The goal of this article is to expand the potential of machine learning approaches to personality assessment by embedding it in a more comprehensive construct validation framework. We review recent applications of machine learning to personality assessment, place machine learning research in the broader context of fundamental principles of construct validation, and provide recommendations for how to use machine learning to advance our understanding of personality.},
  file = {/Users/august/Zotero/storage/JQVJJYY9/Bleidorn and Hopwood - 2019 - Using Machine Learning to Advance Personality Asse.pdf},
  journal = {Personality and Social Psychology Review},
  keywords = {Big Data,Big Five,construct validation,machine learning,personality assessment},
  language = {en},
  number = {2}
}

@article{bojkoEyeTrackingUser2005,
  title = {Eye {{Tracking}} in {{User Experience Testing}}: {{How}} to {{Make}} the {{Most}} of {{It}}},
  shorttitle = {Eye {{Tracking}} in {{User Experience Testing}}},
  author = {Bojko, Agnieszka},
  year = {2005},
  month = jan,
  abstract = {As eye tracking technology becomes more precise, affordable, and unobtrusive, its popularity continues to increase among usability practitioners. This paper introduces eye tracking as a user experience testing tool. It focuses on how to design and conduct studies involving eye tracking, so that eye movement data can effectively supplement data obtained through more conventional methods. Using examples from actual studies, we share lessons learned and provide advice on how to avoid common mistakes.},
  file = {/Users/august/Zotero/storage/WU82XG4M/Bojko - 2005 - Eye Tracking in User Experience Testing How to Ma.pdf},
  journal = {Proceedings of the 14th Annual Conference of the Usability Professionals' Association (UPA). Montr\'eal, Canada}
}

@article{bollerslevGeneralizedAutoregressiveConditional1986,
  title = {Generalized Autoregressive Conditional Heteroskedasticity},
  author = {Bollerslev, Tim},
  year = {1986},
  month = apr,
  volume = {31},
  pages = {307--327},
  issn = {0304-4076},
  doi = {10.1016/0304-4076(86)90063-1},
  abstract = {A natural generalization of the ARCH (Autoregressive Conditional Heteroskedastic) process introduced in Engle (1982) to allow for past conditional variances in the current conditional variance equation is proposed. Stationarity conditions and autocorrelation structure for this new class of parametric models are derived. Maximum likelihood estimation and testing are also considered. Finally an empirical example relating to the uncertainty of the inflation rate is presented.},
  file = {/Users/august/Zotero/storage/ADKZ8E6C/Bollerslev - 1986 - Generalized autoregressive conditional heteroskeda.pdf;/Users/august/Zotero/storage/2A3SUBLM/0304407686900631.html},
  journal = {Journal of Econometrics},
  language = {en},
  number = {3}
}

@inproceedings{bouchardGeneralizableSpatialFeature2016,
  title = {Generalizable Spatial Feature for Human Positioning Based on {{Bluetooth}} Beacons},
  booktitle = {2016 {{IEEE}} 7th {{Annual Ubiquitous Computing}}, {{Electronics Mobile Communication Conference}} ({{UEMCON}})},
  author = {Bouchard, Kevin and Eusufzai, Mahir Rafi and Ramezani, Ramin and Naeim, Arash},
  year = {2016},
  month = oct,
  pages = {1--5},
  doi = {10.1109/UEMCON.2016.7777884},
  abstract = {Every year smaller, cheaper and more precise technologies for ambient intelligence are emerging. One of them has been particularly gaining a lot of traction in the past few year. Indeed, due to their low cost and long battery life, the so-called Bluetooth beacons are being used for a wide range of applications including indoor localization of human. Our team has been using them to gather statistics about room occupancy in health monitoring. In this paper, we consider the beacons signals as time series and we define a new spatial feature that generalize across any configuration (floor plan, beacons number, etc.). The feature is used to distinguish positioning information from the resident. The results of leave-one-out experiments with various floor plans shows promising results.},
  file = {/Users/august/Zotero/storage/L9NA7XDD/Bouchard et al. - 2016 - Generalizable spatial feature for human positionin.pdf},
  keywords = {Activity Recognition,Ambient intelligence,Ambient Intelligence,Batteries,Bluetooth,Data mining,Floors,Health monitoring,Legged locomotion,Medical services,Positioning,Sociology}
}

@inproceedings{cantoniEyeTrackingComputer2014,
  title = {Eye Tracking as a Computer Input and Interaction Method},
  booktitle = {Proceedings of the 15th {{International Conference}} on {{Computer Systems}} and {{Technologies}}},
  author = {Cantoni, Virginio and Porta, Marco},
  year = {2014},
  month = jun,
  pages = {1--12},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2659532.2659592},
  abstract = {Eye tracking applications can be considered under two points of view: in the former the eye tracker is a passive sensor that monitors the eyes to determine what the user is watching. In the latter the eye tracker has an active role that allows the user to control a computer. As a computer input device, an eye tracker typically substitutes the mouse point-select operation with a look-select process to: press buttons, select icons, follow links, etc. While look-select operations are naturally suited to eye input, controlling an interface element is not, because the eyes move covertly by saccades -- quick movements of the point of gaze from one location to another. Since the main task of the eyes is simply to see, if they are also used for interacting with the computer it may be difficult to decide, for example, whether a button is watched to understand its function or to trigger the associated action. In general, eye tracking systems present significant challenges when used for computer input and much research has been carried out in this field.},
  file = {/Users/august/Zotero/storage/FA3TY38J/Cantoni and Porta - 2014 - Eye tracking as a computer input and interaction m.pdf},
  isbn = {978-1-4503-2753-4},
  keywords = {eye tracking,human computer interaction,pointing devices,visual attention},
  series = {{{CompSysTech}} '14}
}

@article{chekroudCrosstrialPredictionTreatment2016,
  title = {Cross-Trial Prediction of Treatment Outcome in Depression: A Machine Learning Approach},
  shorttitle = {Cross-Trial Prediction of Treatment Outcome in Depression},
  author = {Chekroud, Adam Mourad and Zotti, Ryan Joseph and Shehzad, Zarrar and Gueorguieva, Ralitza and Johnson, Marcia K and Trivedi, Madhukar H and Cannon, Tyrone D and Krystal, John Harrison and Corlett, Philip Robert},
  year = {2016},
  month = mar,
  volume = {3},
  pages = {243--250},
  issn = {2215-0366},
  doi = {10.1016/S2215-0366(15)00471-X},
  abstract = {Background Antidepressant treatment efficacy is low, but might be improved by matching patients to interventions. At present, clinicians have no empirically validated mechanisms to assess whether a patient with depression will respond to a specific antidepressant. We aimed to develop an algorithm to assess whether patients will achieve symptomatic remission from a 12-week course of citalopram. Methods We used patient-reported data from patients with depression (n=4041, with 1949 completers) from level 1 of the Sequenced Treatment Alternatives to Relieve Depression (STAR*D; ClinicalTrials.gov, number NCT00021528) to identify variables that were most predictive of treatment outcome, and used these variables to train a machine-learning model to predict clinical remission. We externally validated the model in the escitalopram treatment group (n=151) of an independent clinical trial (Combining Medications to Enhance Depression Outcomes [COMED]; ClinicalTrials.gov, number NCT00590863). Findings We identified 25 variables that were most predictive of treatment outcome from 164 patient-reportable variables, and used these to train the model. The model was internally cross-validated, and predicted outcomes in the STAR*D cohort with accuracy significantly above chance (64{$\cdot$}6\% [SD 3{$\cdot$}2]; p{$<$}0{$\cdot$}0001). The model was externally validated in the escitalopram treatment group (N=151) of COMED (accuracy 59{$\cdot$}6\%, p=0.043). The model also performed significantly above chance in a combined escitalopram-buproprion treatment group in COMED (n=134; accuracy 59{$\cdot$}7\%, p=0{$\cdot$}023), but not in a combined venlafaxine-mirtazapine group (n=140; accuracy 51{$\cdot$}4\%, p=0{$\cdot$}53), suggesting specificity of the model to underlying mechanisms. Interpretation Building statistical models by mining existing clinical trial data can enable prospective identification of patients who are likely to respond to a specific antidepressant. Funding Yale University.},
  file = {/Users/august/Zotero/storage/QS8ZLE8Z/S221503661500471X.html},
  journal = {The Lancet Psychiatry},
  language = {en},
  number = {3}
}

@article{chenAutomaticClassificationEye2013,
  title = {Automatic Classification of Eye Activity for Cognitive Load Measurement with Emotion Interference},
  author = {Chen, Siyuan and Epps, Julien},
  year = {2013},
  month = may,
  volume = {110},
  pages = {111--124},
  issn = {0169-2607},
  doi = {10.1016/j.cmpb.2012.10.021},
  abstract = {Measuring cognitive load changes can contribute to better treatment of patients, can help design effective strategies to reduce medical errors among clinicians and can facilitate user evaluation of health care information systems. This paper proposes an eye-based automatic cognitive load measurement (CLM) system toward realizing these prospects. Three types of eye activity are investigated: pupillary response, blink and eye movement (fixation and saccade). Eye activity features are investigated in the presence of emotion interference, which is a source of undesirable variability, to determine the susceptibility of CLM systems to other factors. Results from an experiment combining arithmetic-based tasks and affective image stimuli demonstrate that arousal effects are dominated by cognitive load during task execution. To minimize the arousal effect on CLM, the choice of segments for eye-based features is examined. We then propose a feature set and classify three levels of cognitive load. The performance of cognitive load level prediction was found to be close to that of a reaction time measure, showing the feasibility of eye activity features for near-real time CLM.},
  file = {/Users/august/Zotero/storage/MTWIHBJ8/Chen and Epps - 2013 - Automatic classification of eye activity for cogni.pdf;/Users/august/Zotero/storage/TFEH2M59/S0169260712002830.html},
  journal = {Computer Methods and Programs in Biomedicine},
  keywords = {Blink,Cognitive load,Eye activity,Eye movement,Fixation,Physiological measures,Pupil,Saccade},
  language = {en},
  number = {2}
}

@article{chengContextMayBe2016,
  title = {Context May Be {{King}}, but Generalizability Is the {{Emperor}}!},
  author = {Cheng, Aaron and Dimoka, Angelika and Pavlou, Paul},
  year = {2016},
  month = sep,
  volume = {31},
  doi = {10.1057/s41265-016-0005-7},
  abstract = {The relative importance of context and generalizability (or particularism and universalism) has long been debated in scientific research. Recently, Davison and Martinsons raised valid concerns about the possibility of false universalism in IS research, discussed its negative consequences, and made a call for explicitly including particularism in research design and reporting. In this commentary, we generally agree with the notion that context should matter more in IS research; yet, the importance of generalizability in research should not be downplayed. Specifically, we posit that generalizability should be given higher position in the scientific process and be the ultimate goal for researchers. Still, researchers need to fully understand the research context, which, in combination and replication, can help to cautiously make generalizable knowledge claims. Therefore, we characterize the relationship between context and generalizability as that of a ?King? (as an analogy of the local role of context) versus the ?Emperor? (as an analogy of the global role of generalizability).},
  file = {/Users/august/Zotero/storage/69DPBLX2/Cheng et al. - 2016 - Context may be King, but generalizability is the E.pdf},
  journal = {Journal of Information Technology}
}

@article{chenUsingTaskInducedPupil2014,
  title = {Using {{Task}}-{{Induced Pupil Diameter}} and {{Blink Rate}} to {{Infer Cognitive Load}}},
  author = {Chen, Siyuan and Epps, Julien},
  year = {2014},
  month = apr,
  volume = {29},
  doi = {10.1080/07370024.2014.892428},
  abstract = {Minimizing user cognitive load is suggested as an integral part of human-centered design, where a more intuitive, easy to learn, and adaptive interface is desired. In this context, it is difficult to develop optimal strategies to improve the design without first knowing how user cognitive load fluctuates during interaction. In this study, we investigate how cognitive load measurement is affected by different task types from the perspective of the load theory of attention, using pupil diameter and blink measures. We induced five levels of cognitive load during low and high perceptual load tasks and found that although pupil diameter showed significant effects on cognitive load when the perceptual load was low, neither blink rate nor pupil diameter showed significant effects on cognitive load when the perceptual load was high. The results indicate that pupil diameter can index cognitive load only in the situation of low perceptual load and are the first to provide empirical support for the cognitive control aspect of the load theory of attention, in the context of cognitive load measurement. Meanwhile, blink is a better indicator of perceptual load than cognitive load. This study also implies that perceptual load should be considered in cognitive load measurement using pupil diameter and blink measures. Automatic detection of the type and level of load in this manner helps pave the way for better reasoning about user internal processes for human-centered interface design.},
  file = {/Users/august/Zotero/storage/QUQHRMFD/Chen and Epps - 2014 - Using Task-Induced Pupil Diameter and Blink Rate t.pdf},
  journal = {Human-Computer Interaction}
}

@article{clarkeNonparametricMultivariateAnalyses1993,
  title = {Nonparametric {{Multivariate Analyses}} of {{Changes}} in {{Community Structure}}},
  author = {Clarke, K.},
  year = {1993},
  month = mar,
  volume = {18},
  pages = {117--143},
  doi = {10.1111/j.1442-9993.1993.tb00438.x},
  abstract = {In the early 1980s, a strategy for graphical representation of multivariate (multi-species) abundance data was introduced into marine ecology by, among others, Field, et al. (1982). A decade on, it is instructive to: (i) identify which elements of this often-quoted strategy have proved most useful in practical assessment of community change resulting from pollution impact; and (ii) ask to what extent evolution of techniques in the intervening years has added self-consistency and comprehensiveness to the approach. The pivotal concept has proved to be that of a biologically-relevant definition of similarity of two samples, and its utilization mainly in simple rank form, for example `sample A is more similar to sample B than it is to sample C'. Statistical assumptions about the data are thus minimized and the resulting non-parametric techniques will be of very general applicability. From such a starting point, a unified framework needs to encompass: (i) the display of community patterns through clustering and ordination of samples; (ii) identification of species principally responsible for determining sample groupings; (iii) statistical tests for differences in space and time (multivariate analogues of analysis of variance, based on rank similarities); and (iv) the linking of community differences to patterns in the physical and chemical environment (the latter also dictated by rank similarities between samples). Techniques are described that bring such a framework into place, and areas in which problems remain are identified. Accumulated practical experience with these methods is discussed, in particular applications to marine benthos, and it is concluded that they have much to offer practitioners of environmental impact studies on communities.},
  file = {/Users/august/Zotero/storage/4EY3ZKXL/Clarke - 1993 - Nonparametric Multivariate Analyses of Changes in .pdf},
  journal = {Austral Ecology}
}

@article{davisonContextKingConsidering2016,
  title = {Context Is King! {{Considering}} Particularism in Research Design and Reporting},
  author = {Davison, Robert M and Martinsons, Maris G},
  year = {2016},
  month = sep,
  volume = {31},
  pages = {241--249},
  publisher = {{SAGE Publications Ltd}},
  issn = {0268-3962},
  doi = {10.1057/jit.2015.19},
  abstract = {We aim to raise awareness of context by examining its role in empirical research. We apply the dichotomy of universalism and particularism, and discuss the interaction of theory and culture in order to consider the scope of validity for research findings and conclusions. We illustrate our arguments by referencing three cases, each of which has contextual inadequacies. We aim to discourage the conduct of research, and acceptance of papers, that falsely implies universalism, relies on convenient samples or ignores indigenous constructs. We offer specific prescriptions for authors, editors and reviewers to help ensure that both the research context and scope of validity are adequately communicated and understood.},
  file = {/Users/august/Zotero/storage/F3PNFZIG/Davison and Martinsons - 2016 - Context is king! Considering particularism in rese.pdf},
  journal = {Journal of Information Technology},
  keywords = {context,culture,particularism,research,theory,universalism},
  language = {en},
  number = {3}
}

@article{DevilDetails2011,
  title = {Devil in the Details},
  year = {2011},
  month = feb,
  volume = {470},
  pages = {305--306},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/470305b},
  abstract = {To ensure their results are reproducible, analysts should show their workings.},
  copyright = {2011 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  file = {/Users/august/Zotero/storage/5UJ5SGQF/2011 - Devil in the details.pdf;/Users/august/Zotero/storage/8ZY6FUVK/470305b.html},
  journal = {Nature},
  language = {en},
  number = {7334}
}

@article{dexterGeneralizationMachineLearning2020,
  title = {Generalization of {{Machine Learning Approaches}} to {{Identify Notifiable Conditions}} from a {{Statewide Health Information Exchange}}},
  author = {Dexter, Gregory P. and Grannis, Shaun J. and Dixon, Brian E. and Kasthurirathne, Suranga N.},
  year = {2020},
  month = may,
  volume = {2020},
  pages = {152--161},
  issn = {2153-4063},
  abstract = {Healthcare analytics is impeded by a lack of machine learning (ML) model generalizability, the ability of a model to predict accurately on varied data sources not included in the model's training dataset. We leveraged free-text laboratory data from a Health Information Exchange network to evaluate ML generalization using Notifiable Condition Detection (NCD) for public health surveillance as a use case. We 1) built ML models for detecting syphilis, salmonella, and histoplasmosis; 2) evaluated generalizability of these models across data from holdout lab systems, and; 3) explored factors that influence weak model generalizability. Models for predicting each disease reported considerable accuracy. However, they demonstrated poor generalizability across data from holdout lab systems being tested. Our evaluation determined that weak generalization was influenced by variant syntactic nature of free-text datasets across each lab system. Results highlight the need for actionable methodology to generalize ML solutions for healthcare analytics.},
  file = {/Users/august/Zotero/storage/X35CTV6M/Dexter et al. - 2020 - Generalization of Machine Learning Approaches to I.pdf},
  journal = {AMIA Summits on Translational Science Proceedings},
  pmcid = {PMC7233074},
  pmid = {32477634}
}

@article{ditommasoNextflowEnablesReproducible2017,
  title = {Nextflow Enables Reproducible Computational Workflows},
  author = {Di Tommaso, Paolo and Chatzou, Maria and Floden, Evan W. and Barja, Pablo Prieto and Palumbo, Emilio and Notredame, Cedric},
  year = {2017},
  month = apr,
  volume = {35},
  pages = {316--319},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1696},
  doi = {10.1038/nbt.3820},
  copyright = {2017 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  file = {/Users/august/Zotero/storage/VBPWNWJZ/Di Tommaso et al. - 2017 - Nextflow enables reproducible computational workfl.pdf;/Users/august/Zotero/storage/56ZF5WXD/nbt.html},
  journal = {Nature Biotechnology},
  language = {en},
  number = {4}
}

@inproceedings{duchowskiIndexPupillaryActivity2018,
  title = {The {{Index}} of {{Pupillary Activity}}: {{Measuring Cognitive Load}} {\emph{Vis-\&\#xe0;-Vis}} {{Task Difficulty}} with {{Pupil Oscillation}}},
  shorttitle = {The {{Index}} of {{Pupillary Activity}}},
  booktitle = {Proceedings of the 2018 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Duchowski, Andrew T. and Krejtz, Krzysztof and Krejtz, Izabela and Biele, Cezary and Niedzielska, Anna and Kiefer, Peter and Raubal, Martin and Giannopoulos, Ioannis},
  year = {2018},
  month = apr,
  pages = {1--13},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3173574.3173856},
  abstract = {A novel eye-tracked measure of the frequency of pupil diameter oscillation is proposed for capturing what is thought to be an indicator of cognitive load. The proposed metric, termed the Index of Pupillary Activity, is shown to discriminate task difficulty vis-a-vis cognitive load (if the implied causality can be assumed) in an experiment where participants performed easy and difficult mental arithmetic tasks while fixating a central target (a requirement for replication of prior work). The paper's contribution is twofold: full documentation is provided for the calculation of the proposed measurement which can be considered as an alternative to the existing proprietary Index of Cognitive Activity (ICA). Thus, it is possible for researchers to replicate the experiment and build their own software which implements this measurement. Second, several aspects of the ICA are approached in a more data-sensitive way with the goal of improving the measurement's performance.},
  file = {/Users/august/Zotero/storage/ZIUSUW3N/Duchowski et al. - 2018 - The Index of Pupillary Activity Measuring Cogniti.pdf},
  isbn = {978-1-4503-5620-6},
  keywords = {eye tracking,pupillometry,task difficulty},
  series = {{{CHI}} '18}
}

@inproceedings{duchowskiLowHighIndex2020,
  title = {The {{Low}}/{{High Index}} of {{Pupillary Activity}}},
  booktitle = {Proceedings of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Duchowski, Andrew T. and Krejtz, Krzysztof and Gehrer, Nina A. and Bafna, Tanya and B{\ae}kgaard, Per},
  year = {2020},
  month = apr,
  pages = {1--12},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3313831.3376394},
  abstract = {A novel eye-tracked measure of pupil diameter oscillation is derived as an indicator of cognitive load. The new metric, termed the Low/High Index of Pupillary Activity (LHIPA), is able to discriminate cognitive load (vis-a-vis task difficulty) in several experiments where the Index of Pupillary Activity fails to do so. Rationale for the LHIPA is tied to the functioning of the human autonomic nervous system yielding a hybrid measure based on the ratio of Low/High frequencies of pupil oscillation. The paper's contribution is twofold. First, full documentation is provided for the calculation of the LHIPA. As with the IPA, it is possible for researchers to apply this metric to their own experiments where a measure of cognitive load is of interest. Second, robustness of the LHIPA is shown in analysis of three experiments, a restrictive fixed-gaze number counting task, a less restrictive fixed-gaze n-back task, and an applied eye-typing task.},
  file = {/Users/august/Zotero/storage/9LNGISLY/Duchowski et al. - 2020 - The LowHigh Index of Pupillary Activity.pdf},
  isbn = {978-1-4503-6708-0},
  keywords = {eye tracking,pupillometry,task difficulty},
  series = {{{CHI}} '20}
}

@article{ferentziMultichannelInvestigationInteroception2018,
  title = {Multichannel {{Investigation}} of {{Interoception}}: {{Sensitivity Is Not}} a {{Generalizable Feature}}},
  shorttitle = {Multichannel {{Investigation}} of {{Interoception}}},
  author = {Ferentzi, Eszter and Bogd{\'a}ny, Tam{\'a}s and Szabolcs, Zsuzsanna and Csala, Barbara and Horv{\'a}th, {\'A}ron and K{\"o}teles, Ferenc},
  year = {2018},
  volume = {12},
  publisher = {{Frontiers}},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2018.00223},
  abstract = {Objective The term interoception refers to the perception of bodily cues. In empirical studies, it is assessed using heartbeat detection or tracking tasks, often with the implicit assumption that cardioception reflects general interoceptive ability. Studies that applied a multichannel approach measured only a limited number of modalities. In the current study, six modalities were assessed to gain a deeper understanding of the relationship between the different sensory channels of interoception. Methods For 118 university students (53\% male) gastric perception (water load test), heartbeat perception (Schandry task), proprioception (elbow joint), ischemic pain (tourniquet technique), balancing ability (one leg stand), and perception of bitter taste were measured. Pair-wise correlation analysis and exploratory factor analyses (principal component analysis and maximum likelihood extraction with oblimin rotation) were then carried out with a three factor solution to investigate the underlying associations. Results Correlation analysis only revealed significant associations between variables belonging to the same sensory modality (gastric perception, pain, bitter taste). Similarly, the three factors that consistently emerged in the factor analyses represented the three aforementioned modalities. Discussion Interoceptive sensitivity assessed by using one channel only cannot be generalized. Interoceptive modalities carrying crucial information for survival are not integrated with other channels.},
  file = {/Users/august/Zotero/storage/QXT8MGZH/Ferentzi et al. - 2018 - Multichannel Investigation of Interoception Sensi.pdf},
  journal = {Frontiers in Human Neuroscience},
  keywords = {balance,Bitter taste,heartbeat perception,interoception,interoceptive sensitivity,Pain,Water load test},
  language = {English}
}

@article{fountain-jonesHowMakeMore2019,
  title = {How to Make More from Exposure Data? {{An}} Integrated Machine Learning Pipeline to Predict Pathogen Exposure},
  shorttitle = {How to Make More from Exposure Data?},
  author = {Fountain-Jones, Nicholas M. and Machado, Gustavo and Carver, Scott and Packer, Craig and Recamonde-Mendoza, Mariana and Craft, Meggan E.},
  year = {2019},
  volume = {88},
  pages = {1447--1461},
  issn = {1365-2656},
  doi = {10.1111/1365-2656.13076},
  abstract = {Predicting infectious disease dynamics is a central challenge in disease ecology. Models that can assess which individuals are most at risk of being exposed to a pathogen not only provide valuable insights into disease transmission and dynamics but can also guide management interventions. Constructing such models for wild animal populations, however, is particularly challenging; often only serological data are available on a subset of individuals and nonlinear relationships between variables are common. Here we provide a guide to the latest advances in statistical machine learning to construct pathogen-risk models that automatically incorporate complex nonlinear relationships with minimal statistical assumptions from ecological data with missing data. Our approach compares multiple machine learning algorithms in a unified environment to find the model with the best predictive performance and uses game theory to better interpret results. We apply this framework on two major pathogens that infect African lions: canine distemper virus (CDV) and feline parvovirus. Our modelling approach provided enhanced predictive performance compared to more traditional approaches, as well as new insights into disease risks in a wild population. We were able to efficiently capture and visualize strong nonlinear patterns, as well as model complex interactions between variables in shaping exposure risk from CDV and feline parvovirus. For example, we found that lions were more likely to be exposed to CDV at a young age but only in low rainfall years. When combined with our data calibration approach, our framework helped us to answer questions about risk of pathogen exposure that are difficult to address with previous methods. Our framework not only has the potential to aid in predicting disease risk in animal populations, but also can be used to build robust predictive models suitable for other ecological applications such as modelling species distribution or diversity patterns.},
  annotation = {\_eprint: https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/1365-2656.13076},
  copyright = {\textcopyright{} 2019 The Authors. Journal of Animal Ecology \textcopyright{} 2019 British Ecological Society},
  file = {/Users/august/Zotero/storage/SJKB3ZBK/Fountain‐Jones et al. - 2019 - How to make more from exposure data An integrated.pdf;/Users/august/Zotero/storage/TQ2WA2JA/1365-2656.html},
  journal = {Journal of Animal Ecology},
  keywords = {boosted regression trees,disease ecology,gradient boosting models,machine learning,model-agnostic methods,random forests,serology,support vector machines},
  language = {en},
  number = {10}
}

@inproceedings{fritzUsingPsychophysiologicalMeasures2014,
  title = {Using Psycho-Physiological Measures to Assess Task Difficulty in Software Development},
  booktitle = {Proceedings of the 36th {{International Conference}} on {{Software Engineering}}},
  author = {Fritz, Thomas and Begel, Andrew and M{\"u}ller, Sebastian C. and {Yigit-Elliott}, Serap and Z{\"u}ger, Manuela},
  year = {2014},
  month = may,
  pages = {402--413},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2568225.2568266},
  abstract = {Software developers make programming mistakes that cause serious bugs for their customers. Existing work to detect problematic software focuses mainly on post hoc identification of correlations between bug fixes and code. We propose a new approach to address this problem --- detect when software developers are experiencing difficulty while they work on their programming tasks, and stop them before they can introduce bugs into the code. In this paper, we investigate a novel approach to classify the difficulty of code comprehension tasks using data from psycho-physiological sensors. We present the results of a study we conducted with 15 professional programmers to see how well an eye-tracker, an electrodermal activity sensor, and an electroencephalography sensor could be used to predict whether developers would find a task to be difficult. We can predict nominal task difficulty (easy/difficult) for a new developer with 64.99\% precision and 64.58\% recall, and for a new task with 84.38\% precision and 69.79\% recall. We can improve the Naive Bayes classifier's performance if we trained it on just the eye-tracking data over the entire dataset, or by using a sliding window data collection schema with a 55 second time window. Our work brings the community closer to a viable and reliable measure of task difficulty that could power the next generation of programming support tools.},
  file = {/Users/august/Zotero/storage/4C5J3B8V/Fritz et al. - 2014 - Using psycho-physiological measures to assess task.pdf},
  isbn = {978-1-4503-2756-5},
  keywords = {psycho-physiological,study,task difficulty},
  series = {{{ICSE}} 2014}
}

@article{grankaEyeTrackingAnalysisUser2004,
  title = {Eye-{{Tracking Analysis}} of {{User Behavior}} in {{WWW}}-{{Search}}},
  author = {Granka, Laura and Joachims, Thorsten and Gay, Geri},
  year = {2004},
  month = apr,
  doi = {10.1145/1008992.1009079},
  abstract = {We investigate how users interact with the results page of a WWW search engine using eye-tracking. The goal is to gain insight into how users browse the presented abstracts and how they select links for further exploration. Such understanding is valuable for improved interface design, as well as for more accurate interpretations of implicit feedback (e.g. clickthrough) for machine learning. The following presents initial results, focusing on the amount of time spent viewing the presented abstracts, the total number of abstract viewed, as well as data like query word frequency [6]. Howev tracking, these measurements can at best give in diameter, as a lar measures of how thoroughly searchers evaluate their results set.},
  file = {/Users/august/Zotero/storage/Y5T4CUFN/Granka et al. - 2004 - Eye-Tracking Analysis of User Behavior in WWW-Sear.pdf},
  journal = {Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval}
}

@article{guzzettaMachineLearningPipeline2010,
  title = {A Machine Learning Pipeline for Quantitative Phenotype Prediction from Genotype Data},
  author = {Guzzetta, Giorgio and Jurman, Giuseppe and Furlanello, Cesare},
  year = {2010},
  month = oct,
  volume = {11},
  pages = {S3},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-11-S8-S3},
  abstract = {Quantitative phenotypes emerge everywhere in systems biology and biomedicine due to a direct interest for quantitative traits, or to high individual variability that makes hard or impossible to classify samples into distinct categories, often the case with complex common diseases. Machine learning approaches to genotype-phenotype mapping may significantly improve Genome-Wide Association Studies (GWAS) results by explicitly focusing on predictivity and optimal feature selection in a multivariate setting. It is however essential that stringent and well documented Data Analysis Protocols (DAP) are used to control sources of variability and ensure reproducibility of results. We present a genome-to-phenotype pipeline of machine learning modules for quantitative phenotype prediction. The pipeline can be applied for the direct use of whole-genome information in functional studies. As a realistic example, the problem of fitting complex phenotypic traits in heterogeneous stock mice from single nucleotide polymorphims (SNPs) is here considered.},
  file = {/Users/august/Zotero/storage/NGY8GLDC/Guzzetta et al. - 2010 - A machine learning pipeline for quantitative pheno.pdf;/Users/august/Zotero/storage/JSVJCQLG/1471-2105-11-S8-S3.html},
  journal = {BMC Bioinformatics},
  keywords = {Mean Cell Haemoglobin,Monte Carlo Markov Chain,Quantitative Phenotype,Regularize Little Square,Support Vector Regression},
  number = {8}
}

@inproceedings{haapalainenPsychophysiologicalMeasuresAssessing2010,
  title = {Psycho-Physiological Measures for Assessing Cognitive Load},
  booktitle = {Proceedings of the 12th {{ACM}} International Conference on {{Ubiquitous}} Computing},
  author = {Haapalainen, Eija and Kim, SeungJun and Forlizzi, Jodi F. and Dey, Anind K.},
  year = {2010},
  month = sep,
  pages = {301--310},
  publisher = {{ACM}},
  address = {{Copenhagen Denmark}},
  doi = {10.1145/1864349.1864395},
  abstract = {With a focus on presenting information at the right time, the ubicomp community can benefit greatly from learning the most salient human measures of cognitive load. Cognitive load can be used as a metric to determine when or whether to interrupt a user. In this paper, we collected data from multiple sensors and compared their ability to assess cognitive load. Our focus is on visual perception and cognitive speed-focused tasks that leverage cognitive abilities common in ubicomp applications. We found that across all participants, the electrocardiogram median absolute deviation and median heat flux measurements were the most accurate at distinguishing between low and high levels of cognitive load, providing a classification accuracy of over 80\% when used together. Our contribution is a real-time, objective, and generalizable method for assessing cognitive load in cognitive tasks commonly found in ubicomp systems and situations of divided attention.},
  file = {/Users/august/Zotero/storage/UBNRN5X6/Haapalainen et al. - 2010 - Psycho-physiological measures for assessing cognit.pdf},
  isbn = {978-1-60558-843-8},
  language = {en}
}

@inproceedings{huttTimeScaleGeneralizable2019,
  title = {Time to {{Scale}}: {{Generalizable Affect Detection}} for {{Tens}} of {{Thousands}} of {{Students}} across {{An Entire School Year}}},
  shorttitle = {Time to {{Scale}}},
  booktitle = {{{CHI}} '19: {{Proceedings}} of the 2019 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Hutt, Stephen and Grafsgaard, Joseph and D'Mello, Sidney},
  year = {2019},
  month = apr,
  pages = {1--14},
  doi = {10.1145/3290605.3300726},
  abstract = {We developed generalizable affect detectors using 133,966 instances of 18 affective states collected from 69,174 students who interacted with an online math learning platform called Algebra Nation over the entire school year. To enable scalability and generalizability, we used generic interaction features (e.g., viewing a video, taking a quiz), which do not require specialized sensors and are domain- and (to a certain extent) system-independent. We experimented with standard classifiers, recurrent neural networks, and genetically evolved neural networks for affect modeling. Prediction accuracies, quantified with Spearman's rho, were modest and ranged from .08 (for surprise) to .34 (for happiness) with a mean of .25. Our model trained on Algebra students generalized to a different set of Geometry students (n = 28,458) on the same platform. We discuss implications for scaling up affect detection for affect-sensitive online learning environments which aim to improve engagement and learning by detecting and responding to student affect.},
  isbn = {978-1-4503-5970-2}
}

@article{inceCaseOpenComputer2012,
  title = {The Case for Open Computer Programs},
  author = {Ince, Darrel C. and Hatton, Leslie and {Graham-Cumming}, John},
  year = {2012},
  month = feb,
  volume = {482},
  pages = {485--488},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature10836},
  abstract = {Scientific reproducibility now very often depends on the computational method being available to duplicate, so here it is argued that all source code should be freely available.},
  copyright = {2012 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  file = {/Users/august/Zotero/storage/K8F26L9K/Ince et al. - 2012 - The case for open computer programs.pdf;/Users/august/Zotero/storage/UIMLIEGZ/nature10836.html},
  journal = {Nature},
  language = {en},
  number = {7386}
}

@incollection{johnIrrelevantFeaturesSubset1994,
  title = {Irrelevant {{Features}} and the {{Subset Selection Problem}}},
  booktitle = {Machine {{Learning Proceedings}} 1994},
  author = {John, George H. and Kohavi, Ron and Pfleger, Karl},
  year = {1994},
  pages = {121--129},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-1-55860-335-6.50023-4},
  abstract = {We address the problem of nding a subset of features that allows a supervised induction algorithm to induce small high-accuracy concepts. We examine notions of relevance and irrelevance, and show that the de nitions used in the machine learning literature do not adequately partition the features into useful categories of relevance. We present de nitions for irrelevance and for two degrees of relevance. These de nitions improve our understanding of the behavior of previous subset selection algorithms, and help de ne the subset of features that should be sought. The features selected should depend not only on the features and the target concept, but also on the induction algorithm. We describe a method for feature subset selection using cross-validation that is applicable to any induction algorithm, and discuss experiments conducted with ID3 and C4.5 on arti cial and real datasets.},
  file = {/Users/august/Zotero/storage/KWMZQY9N/John et al. - 1994 - Irrelevant Features and the Subset Selection Probl.pdf},
  isbn = {978-1-55860-335-6},
  language = {en}
}

@inproceedings{kimDecodingLearningStrategies2021,
  title = {Decoding Learning Strategies from {{EEG}} Signals Provides Generalizable Features for Decoding Decision},
  booktitle = {2021 9th {{International Winter Conference}} on {{Brain}}-{{Computer Interface}} ({{BCI}})},
  author = {Kim, Dongjae and Kim, Myeong Hyeon and Lee, Sang Wan},
  year = {2021},
  month = feb,
  pages = {1--5},
  issn = {2572-7672},
  doi = {10.1109/BCI51272.2021.9385334},
  abstract = {Recent studies have demonstrated that learning strategies can be decoded from EEG data using a computational model of model-based and model-free reinforcement learning. The results raise expectations for improving the decodability of decisions in a broader context because the decision is an inherent part of the learning strategies. In this study, we investigated this possibility using various information theory-based methods. First, we trained a simple deep neural network to decode learning strategies from EEG signals collected while human subjects perform a strategy learning task with context changes. We then evaluated the ability of the model to decode subjective decision signals from EEG signals in another decision-making scenario that was not used during training. This zero-training scheme allows us to investigate whether the learning strategy decoder gleans information generalizable to various decision-making scenarios. Notably, we found that the decoder contains a significant amount of mutual information between input, hidden, and output for the new data (decision-making task; \$\textbackslash mathrmp {$<$} 5\textbackslash mathrme-2\$), as well as the original training data (strategy learning task; \$\textbackslash mathrmp {$<$} 1\textbackslash mathrme-5\$). In subsequent analyses of the neural representations of the model's hidden layers, we found informative features for decoding decisions in its deep layers. The results suggest that decoding learning strategies will help design generalizable EEG decoders.},
  file = {/Users/august/Zotero/storage/UA23G65J/Kim et al. - 2021 - Decoding learning strategies from EEG signals prov.pdf;/Users/august/Zotero/storage/9M76SFNS/9385334.html},
  keywords = {Brain modeling,Brain-computer interface,Data models,Decision making,Decoding,Deep learning,Electroencephalography,Feature extraction,Information theory,Learning strategy,Reinforcement learning,Task analysis}
}

@article{kraskaMLbaseDistributedMachinelearning,
  title = {{{MLbase}}: {{A Distributed Machine}}-Learning {{System}}},
  author = {Kraska, Tim and Talwalkar, Ameet and Duchi, John},
  pages = {7},
  abstract = {Machine learning (ML) and statistical techniques are key to transforming big data into actionable knowledge. In spite of the modern primacy of data, the complexity of existing ML algorithms is often overwhelming\textemdash many users do not understand the trade-offs and challenges of parameterizing and choosing between different learning techniques. Furthermore, existing scalable systems that support machine learning are typically not accessible to ML researchers without a strong background in distributed systems and low-level primitives. In this work, we present our vision for MLbase, a novel system harnessing the power of machine learning for both end-users and ML researchers. MLbase provides (1) a simple declarative way to specify ML tasks, (2) a novel optimizer to select and dynamically adapt the choice of learning algorithm, (3) a set of high-level operators to enable ML researchers to scalably implement a wide range of ML methods without deep systems knowledge, and (4) a new run-time optimized for the data-access patterns of these high-level operators.},
  file = {/Users/august/Zotero/storage/NYDN8QPW/Kraska et al. - MLbase A Distributed Machine-learning System.pdf},
  language = {en}
}

@article{lopezgarciaCloudBasedFrameworkMachine2020,
  title = {A {{Cloud}}-{{Based Framework}} for {{Machine Learning Workloads}} and {{Applications}}},
  author = {L{\'o}pez Garc{\'i}a, {\'A}lvaro and De Lucas, Jes{\'u}s Marco and Antonacci, Marica and Zu Castell, Wolfgang and David, Mario and Hardt, Marcus and Lloret Iglesias, Lara and Molt{\'o}, Germ{\'a}n and Plociennik, Marcin and Tran, Viet and Alic, Andy S. and Caballer, Miguel and Plasencia, Isabel Campos and Costantini, Alessandro and Dlugolinsky, Stefan and Duma, Doina Cristina and Donvito, Giacinto and Gomes, Jorge and Heredia Cacha, Ignacio and Ito, Keiichi and Kozlov, Valentin Y. and Nguyen, Giang and Orviz Fern{\'a}ndez, Pablo and {\v S}ustr, Zd{\v e}nek and Wolniewicz, Pawel},
  year = {2020},
  volume = {8},
  pages = {18681--18692},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.2964386},
  abstract = {In this paper we propose a distributed architecture to provide machine learning practitioners with a set of tools and cloud services that cover the whole machine learning development cycle: ranging from the models creation, training, validation and testing to the models serving as a service, sharing and publication. In such respect, the DEEP-Hybrid-DataCloud framework allows transparent access to existing e-Infrastructures, effectively exploiting distributed resources for the most compute-intensive tasks coming from the machine learning development cycle. Moreover, it provides scientists with a set of Cloud-oriented services to make their models publicly available, by adopting a serverless architecture and a DevOps approach, allowing an easy share, publish and deploy of the developed models.},
  file = {/Users/august/Zotero/storage/2KUE8YMD/López García et al. - 2020 - A Cloud-Based Framework for Machine Learning Workl.pdf;/Users/august/Zotero/storage/3VUEFK3I/8950411.html},
  journal = {IEEE Access},
  keywords = {Cloud computing,Computational modeling,Computer architecture,computers and information processing,deep learning,Deep learning,distributed computing,machine learning,serverless architectures,Task analysis,Tools}
}

@misc{LowHighIndex,
  title = {The {{Low}}/{{High Index}} of {{Pupillary Activity}} | {{Proceedings}} of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  file = {/Users/august/Zotero/storage/KVIR3VAS/3313831.html},
  howpublished = {https://dl.acm.org/doi/abs/10.1145/3313831.3376394}
}

@misc{MachineLearningArtificial,
  title = {Machine Learning and Artificial Intelligence Research for Patient Benefit: 20 Critical Questions on Transparency, Replicability, Ethics, and Effectiveness | {{The BMJ}}},
  file = {/Users/august/Zotero/storage/JSBTZ8TP/bmj.l6927.html},
  howpublished = {https://www.bmj.com/content/368/bmj.l6927.abstract}
}

@inproceedings{mcnallyPredictingPriceBitcoin2018,
  title = {Predicting the {{Price}} of {{Bitcoin Using Machine Learning}}},
  booktitle = {2018 26th {{Euromicro International Conference}} on {{Parallel}}, {{Distributed}} and {{Network}}-Based {{Processing}} ({{PDP}})},
  author = {McNally, Sean and Roche, Jason and Caton, Simon},
  year = {2018},
  month = mar,
  pages = {339--343},
  issn = {2377-5750},
  doi = {10.1109/PDP2018.2018.00060},
  abstract = {The goal of this paper is to ascertain with what accuracy the direction of Bitcoin price in USD can be predicted. The price data is sourced from the Bitcoin Price Index. The task is achieved with varying degrees of success through the implementation of a Bayesian optimised recurrent neural network (RNN) and a Long Short Term Memory (LSTM) network. The LSTM achieves the highest classification accuracy of 52\% and a RMSE of 8\%. The popular ARIMA model for time series forecasting is implemented as a comparison to the deep learning models. As expected, the non-linear deep learning methods outperform the ARIMA forecast which performs poorly. Finally, both deep learning models are benchmarked on both a GPU and a CPU with the training time on the GPU outperforming the CPU implementation by 67.7\%.},
  file = {/Users/august/Zotero/storage/BTI2A3WD/8374483.html},
  keywords = {ARIMA,Bitcoin,Deep Learning,GPU,Graphics processing units,Long Short Term Memory,Machine learning,Predictive models,Recurrent Neural Network,Task analysis,Time series analysis,Training}
}

@article{mohrPredictingMachineLearning2021,
  title = {Predicting {{Machine Learning Pipeline Runtimes}} in the {{Context}} of {{Automated Machine Learning}}},
  author = {Mohr, Felix and Wever, Marcel and Tornede, Alexander and Hullermeier, Eyke},
  year = {2021},
  pages = {1--1},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2021.3056950},
  abstract = {Automated Machine Learning (AutoML) seeks to automatically find so-called machine learning pipelines that maximize the prediction performance when being used to train a model on a given dataset. One of the main and yet open challenges in AutoML is an effective use of computational resources: An AutoML process involves the evaluation of many candidate pipelines, which are costly but often ineffective because they are canceled due to a timeout. In this paper, we present an approach to predict the runtime of two-step machine learning pipelines with up to one pre-processor, which can be used to anticipate whether or not a pipeline will time out. Separate runtime models are trained offline for each algorithm that may be used in a pipeline, and an overall prediction is derived from these models. We empirically show that the approach increases successful evaluations made by an AutoML tool while preserving or even improving on the previously best solutions.},
  file = {/Users/august/Zotero/storage/EHB8MAW5/Mohr et al. - 2021 - Predicting Machine Learning Pipeline Runtimes in t.pdf;/Users/august/Zotero/storage/P8MBEP3W/9347828.html},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  keywords = {automated machine learning,hierarchical runtime prediction,Machine learning,Machine learning algorithms,Pipelines,Prediction algorithms,Predictive models,Runtime,runtime prediction for classifiers and pipelines,Tools}
}

@article{naglerSustainabilityReproducibilityContainerized2015,
  title = {Sustainability and {{Reproducibility}} via {{Containerized Computing}}},
  author = {Nagler, Robert and Bruhwiler, David and Moeller, Paul and Webb, Stephen},
  year = {2015},
  month = sep,
  abstract = {Recent developments in the commercial open source community have catalysed the use of Linux containers for scalable deployment of web-based applications to the cloud. Scientific software can be containerized with dependencies, configuration files, post-processing tools and even simulation results, referred to as containerized computing. This new approach promises to significantly improve sustainability, productivity and reproducibility. We present our experiences, technology, and future plans for open source containerization of software used to model particle and radiation beams. Vagrant is central to our approach, using Docker for cloud deployment and VirtualBox virtual machines for deployment to Mac OS and Windows computers. Our technology enables seamless switching between the desktop and the cloud to simplify simulation development and execution.},
  archiveprefix = {arXiv},
  eprint = {1509.08789},
  eprinttype = {arxiv},
  file = {/Users/august/Zotero/storage/5T3GTHS5/Nagler et al. - 2015 - Sustainability and Reproducibility via Containeriz.pdf;/Users/august/Zotero/storage/MFAAJ2M6/1509.html},
  journal = {arXiv:1509.08789 [cs]},
  keywords = {Computer Science - Software Engineering,D.2.12,D.2.m,K.6.1,K.6.3},
  note = {Comment: 2 pages},
  primaryclass = {cs}
}

@article{nguyenMachineLearningDeep2019,
  title = {Machine {{Learning}} and {{Deep Learning}} Frameworks and Libraries for Large-Scale Data Mining: A Survey},
  shorttitle = {Machine {{Learning}} and {{Deep Learning}} Frameworks and Libraries for Large-Scale Data Mining},
  author = {Nguyen, Giang and Dlugolinsky, Stefan and Bob{\'a}k, Martin and Tran, Viet and L{\'o}pez Garc{\'i}a, {\'A}lvaro and Heredia, Ignacio and Mal{\'i}k, Peter and Hluch{\'y}, Ladislav},
  year = {2019},
  month = jun,
  volume = {52},
  pages = {77--124},
  issn = {1573-7462},
  doi = {10.1007/s10462-018-09679-z},
  abstract = {The combined impact of new computing resources and techniques with an increasing avalanche of large datasets, is transforming many research areas and may lead to technological breakthroughs that can be used by billions of people. In the recent years, Machine Learning and especially its subfield Deep Learning have seen impressive advances. Techniques developed within these two fields are now able to analyze and learn from huge amounts of real world examples in a disparate formats. While the number of Machine Learning algorithms is extensive and growing, their implementations through frameworks and libraries is also extensive and growing too. The software development in this field is fast paced with a large number of open-source software coming from the academy, industry, start-ups or wider open-source communities. This survey presents a recent time-slide comprehensive overview with comparisons as well as trends in development and usage of cutting-edge Artificial Intelligence software. It also provides an overview of massive parallelism support that is capable of scaling computation effectively and efficiently in the era of Big Data.},
  file = {/Users/august/Zotero/storage/9W3M5MRY/Nguyen et al. - 2019 - Machine Learning and Deep Learning frameworks and .pdf},
  journal = {Artificial Intelligence Review},
  language = {en},
  number = {1}
}

@article{nurseGeneralizableBrainComputerInterface2015,
  title = {A {{Generalizable Brain}}-{{Computer Interface}} ({{BCI}}) {{Using Machine Learning}} for {{Feature Discovery}}},
  author = {Nurse, Ewan S. and Karoly, Philippa J. and Grayden, David B. and Freestone, Dean R.},
  year = {2015},
  month = jun,
  volume = {10},
  pages = {e0131328},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0131328},
  abstract = {This work describes a generalized method for classifying motor-related neural signals for a brain-computer interface (BCI), based on a stochastic machine learning method. The method differs from the various feature extraction and selection techniques employed in many other BCI systems. The classifier does not use extensive a-priori information, resulting in reduced reliance on highly specific domain knowledge. Instead of pre-defining features, the time-domain signal is input to a population of multi-layer perceptrons (MLPs) in order to perform a stochastic search for the best structure. The results showed that the average performance of the new algorithm outperformed other published methods using the Berlin BCI IV (2008) competition dataset and was comparable to the best results in the Berlin BCI II (2002\textendash 3) competition dataset. The new method was also applied to electroencephalography (EEG) data recorded from five subjects undertaking a hand squeeze task and demonstrated high levels of accuracy with a mean classification accuracy of 78.9\% after five-fold cross-validation. Our new approach has been shown to give accurate results across different motor tasks and signal types as well as between subjects.},
  file = {/Users/august/Zotero/storage/H3JCJWET/Nurse et al. - 2015 - A Generalizable Brain-Computer Interface (BCI) Usi.pdf;/Users/august/Zotero/storage/QNWM9P3G/article.html},
  journal = {PLOS ONE},
  keywords = {Artificial neural networks,Electroencephalography,Hands,Machine learning,Machine learning algorithms,Man-computer interface,Neurons,Signaling networks},
  language = {en},
  number = {6}
}

@incollection{olsenUsingIntelligentTutoring2014,
  title = {Using an {{Intelligent Tutoring System}} to {{Support Collaborative}} as Well as {{Individual Learning}}},
  booktitle = {Intelligent {{Tutoring Systems}}},
  author = {Olsen, Jennifer K. and Belenky, Daniel M. and Aleven, Vincent and Rummel, Nikol},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Kobsa, Alfred and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Terzopoulos, Demetri and Tygar, Doug and Weikum, Gerhard and {Trausan-Matu}, Stefan and Boyer, Kristy Elizabeth and Crosby, Martha and Panourgia, Kitty},
  year = {2014},
  volume = {8474},
  pages = {134--143},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-07221-0_16},
  abstract = {Collaborative learning has been shown to be beneficial for older students, but there has not been much research to show if these results transfer to elementary school students. In addition, collaborative and individual modes of instruction may be better for acquiring different types of knowledge. Collaborative Intelligent Tutoring Systems (ITS) provide a platform that may be able to provide both the cognitive and collaborative support that students need. This paper presents a study comparing collaborative and individual methods while receiving instruction on either procedural or conceptual knowledge. The collaborative groups had the same learning gains as the individual groups in both the procedural and conceptual learning conditions but were able to do so with fewer problems. This work indicates that by embedding collaboration scripts in ITSs, collaborative learning can be an effective instructional method even with young children.},
  file = {/Users/august/Zotero/storage/VXZ67JJN/Olsen et al. - 2014 - Using an Intelligent Tutoring System to Support Co.pdf},
  isbn = {978-3-319-07220-3 978-3-319-07221-0},
  language = {en}
}

@inproceedings{olsonEvaluationTreebasedPipeline2016,
  title = {Evaluation of a {{Tree}}-Based {{Pipeline Optimization Tool}} for {{Automating Data Science}}},
  booktitle = {Proceedings of the {{Genetic}} and {{Evolutionary Computation Conference}} 2016},
  author = {Olson, Randal S. and Bartley, Nathan and Urbanowicz, Ryan J. and Moore, Jason H.},
  year = {2016},
  month = jul,
  pages = {485--492},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2908812.2908918},
  abstract = {As the field of data science continues to grow, there will be an ever-increasing demand for tools that make machine learning accessible to non-experts. In this paper, we introduce the concept of tree-based pipeline optimization for automating one of the most tedious parts of machine learning--pipeline design. We implement an open source Tree-based Pipeline Optimization Tool (TPOT) in Python and demonstrate its effectiveness on a series of simulated and real-world benchmark data sets. In particular, we show that TPOT can design machine learning pipelines that provide a significant improvement over a basic machine learning analysis while requiring little to no input nor prior knowledge from the user. We also address the tendency for TPOT to design overly complex pipelines by integrating Pareto optimization, which produces compact pipelines without sacrificing classification accuracy. As such, this work represents an important step toward fully automating machine learning pipeline design.},
  file = {/Users/august/Zotero/storage/8YP4AT2W/Olson et al. - 2016 - Evaluation of a Tree-based Pipeline Optimization T.pdf},
  isbn = {978-1-4503-4206-3},
  keywords = {data science,genetic programming,hyperparameter optimization,machine learning,Pareto optimization,pipeline optimization,python},
  series = {{{GECCO}} '16}
}

@incollection{olsonTPOTTreeBasedPipeline2019,
  title = {{{TPOT}}: {{A Tree}}-{{Based Pipeline Optimization Tool}} for {{Automating Machine Learning}}},
  shorttitle = {{{TPOT}}},
  author = {Olson, Randal and Moore, Jason},
  year = {2019},
  month = may,
  pages = {151--160},
  doi = {10.1007/978-3-030-05318-5_8},
  abstract = {As data science becomes increasingly mainstream, there will be an ever-growing demand for data science tools that are more accessible, flexible, and scalable. In response to this demand, automated machine learning (AutoML) researchers have begun building systems that automate the process of designing and optimizing machine learning pipelines. In this chapter we present TPOT v0.3, an open source genetic programming-based AutoML system that optimizes a series of feature preprocessors and machine learning models with the goal of maximizing classification accuracy on a supervised classification task. We benchmark TPOT on a series of 150 supervised classification tasks and find that it significantly outperforms a basic machine learning analysis in 21 of them, while experiencing minimal degradation in accuracy on 4 of the benchmarks\textemdash all without any domain knowledge nor human input. As such, genetic programming-based AutoML systems show considerable promise in the AutoML domain.},
  file = {/Users/august/Zotero/storage/NC3QG5CU/Olson and Moore - 2019 - TPOT A Tree-Based Pipeline Optimization Tool for .pdf},
  isbn = {978-3-030-05317-8}
}

@article{pedregosaScikitlearnMachineLearning,
  title = {Scikit-Learn: {{Machine Learning}} in {{Python}}},
  author = {Pedregosa, Fabian and Varoquaux, Gael and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David},
  pages = {6},
  abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
  file = {/Users/august/Zotero/storage/U98W7GDB/Pedregosa et al. - Scikit-learn Machine Learning in Python.pdf},
  journal = {MACHINE LEARNING IN PYTHON},
  language = {en}
}

@article{pelanekMetricsEvaluationStudent2015,
  title = {Metrics for {{Evaluation}} of {{Student Models}}},
  author = {Pelanek, Radek},
  year = {2015},
  volume = {7},
  pages = {1--19},
  publisher = {{International Educational Data Mining}},
  issn = {2157-2100},
  abstract = {Researchers use many different metrics for evaluation of performance of student models. The aim of this paper is to provide an overview of commonly used metrics, to discuss properties, advantages, and disadvantages of different metrics, to summarize current practice in educational data mining, and to provide guidance for evaluation of student models. In the discussion we mention the relation of metrics to parameter fitting, the impact of student models on student practice (over-practice, under-practice), and point out connections to related work on evaluation of probability forecasters in other domains. We also provide an empirical comparison of metrics. One of the conclusion of the paper is that some commonly used metrics should not be used (MAE) or should be used more critically (AUC).},
  file = {/Users/august/Zotero/storage/T42GLLKZ/Pelanek - 2015 - Metrics for Evaluation of Student Models.pdf;/Users/august/Zotero/storage/FRX2TCM4/eric.ed.gov.html},
  journal = {Journal of Educational Data Mining},
  keywords = {Affective Measures,Data Analysis,Data Interpretation,Data Processing,Error of Measurement,Evaluation Criteria,Evaluation Methods,Goodness of Fit,Measurement Techniques,Models,Probability,Qualitative Research,Reliability,Scoring Rubrics,Skill Analysis,Student Records,Usability},
  language = {en},
  number = {2}
}

@article{pengReproducibleResearchComputational2011,
  title = {Reproducible {{Research}} in {{Computational Science}}},
  author = {Peng, Roger D.},
  year = {2011},
  month = dec,
  volume = {334},
  pages = {1226--1227},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1213847},
  abstract = {Computational science has led to exciting new developments, but the nature of the work has exposed limitations in our ability to evaluate published findings. Reproducibility has the potential to serve as a minimum standard for judging scientific claims when full independent replication of a study is not possible.},
  chapter = {Perspective},
  copyright = {Copyright \textcopyright{} 2011, American Association for the Advancement of Science},
  file = {/Users/august/Zotero/storage/RWUMRQ7B/Peng - 2011 - Reproducible Research in Computational Science.pdf;/Users/august/Zotero/storage/5PQR4KF3/1226.html},
  journal = {Science},
  language = {en},
  number = {6060},
  pmid = {22144613}
}

@inproceedings{phillipsGeneralizableIntentionPrediction2017,
  title = {Generalizable Intention Prediction of Human Drivers at Intersections},
  booktitle = {2017 {{IEEE Intelligent Vehicles Symposium}} ({{IV}})},
  author = {Phillips, Derek J. and Wheeler, Tim A. and Kochenderfer, Mykel J.},
  year = {2017},
  month = jun,
  pages = {1665--1670},
  doi = {10.1109/IVS.2017.7995948},
  abstract = {Effective navigation of urban environments is a primary challenge remaining in the development of autonomous vehicles. Intersections come in many shapes and forms, making it difficult to find features and models that generalize across intersection types. New and traditional features are used to train several intersection intention models on real-world intersection data, and a new class of recurrent neural networks, Long Short Term Memory networks (LSTMs), are shown to outperform the state of the art. The models predict whether a driver will turn left, turn right, or continue straight up to 150 m with consistent accuracy before reaching the intersection. The results show promise for further use of LSTMs, with the mean cross validated prediction accuracy averaging over 85\% for both three and four-way intersections, obtaining 83\% for the highest throughput intersection.},
  file = {/Users/august/Zotero/storage/EZVSTVET/Phillips et al. - 2017 - Generalizable intention prediction of human driver.pdf;/Users/august/Zotero/storage/PYLMD22W/7995948.html},
  keywords = {Data models,Feature extraction,Hidden Markov models,Navigation,Predictive models,Recurrent neural networks,Vehicles}
}

@misc{PredictionMOOCsReview,
  title = {Prediction in {{MOOCs}}: {{A Review}} and {{Future Research Directions}}},
  shorttitle = {Prediction in {{MOOCs}}},
  abstract = {This paper surveys the state of the art on prediction in MOOCs through a systematic literature review (SLR). The main objectives are: first, to identify the characteristics of the MOOCs used for prediction, second, to describe the prediction outcomes, third, to classify the prediction features, fourth, to determine the techniques used to predict the variables, and, fifth, to identify the metrics used to evaluate the predictive models. Results show there is strong interest in predicting dropouts in MOOCs. A variety of predictive models are used, though regression and support vector machines stand out. There is also wide variety in the choice of prediction features, but clickstream data about platform use stands out. Future research should focus on developing and applying predictive models that can be used in more heterogeneous contexts (in terms of platforms, thematic areas, and course durations), on predicting new outcomes and making connections among them (e.g., predicting learners' expectancies), on enhancing the predictive power of current models by improving algorithms or adding novel higher-order features (e.g., efficiency, constancy, etc.).},
  file = {/Users/august/Zotero/storage/L8GA2TGW/8412110.html},
  howpublished = {https://ieeexplore.ieee.org/document/8412110},
  language = {en-US}
}

@article{ramGitCanFacilitate2013,
  title = {Git Can Facilitate Greater Reproducibility and Increased Transparency in Science},
  author = {Ram, Karthik},
  year = {2013},
  month = feb,
  volume = {8},
  pages = {7},
  issn = {1751-0473},
  doi = {10.1186/1751-0473-8-7},
  abstract = {Reproducibility is the hallmark of good science. Maintaining a high degree of transparency in scientific reporting is essential not just for gaining trust and credibility within the scientific community but also for facilitating the development of new ideas. Sharing data and computer code associated with publications is becoming increasingly common, motivated partly in response to data deposition requirements from journals and mandates from funders. Despite this increase in transparency, it is still difficult to reproduce or build upon the findings of most scientific publications without access to a more complete workflow.},
  file = {/Users/august/Zotero/storage/WB38HC76/Ram - 2013 - Git can facilitate greater reproducibility and inc.pdf;/Users/august/Zotero/storage/HQDTEMLV/1751-0473-8-7.html},
  journal = {Source Code for Biology and Medicine},
  keywords = {Open science,Reproducible research,Version control},
  number = {1}
}

@inproceedings{raptisUsingEyeGaze2017,
  title = {Using {{Eye Gaze Data}} and {{Visual Activities}} to {{Infer Human Cognitive Styles}}: {{Method}} and {{Feasibility Studies}}},
  shorttitle = {Using {{Eye Gaze Data}} and {{Visual Activities}} to {{Infer Human Cognitive Styles}}},
  booktitle = {Proceedings of the 25th {{Conference}} on {{User Modeling}}, {{Adaptation}} and {{Personalization}}},
  author = {Raptis, George E. and Katsini, Christina and Belk, Marios and Fidas, Christos and Samaras, George and Avouris, Nikolaos},
  year = {2017},
  month = jul,
  pages = {164--173},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3079628.3079690},
  abstract = {Recent research provides evidence that individual differences in human cognitive styles affect user performance and experience in diverse application domains. However, state-of-the-art elicitation methods of cognitive styles require researchers to apply explicit, in-lab, and time-consuming "paper-and-pencil" techniques, rendering real-time integration of cognitive styles? elicitation impractical in interactive system design. Aiming to elaborate an implicit elicitation method of cognitive styles, this paper reports two feasibility studies based on an eye-tracking multifactorial model. In both studies, participants performed visual activities of varying characteristics, and the eye-tracking analysis revealed quantitative differences on visual behavior among individuals with different cognitive styles. Based on these differences, a series of classification experiments were conducted, and the results revealed that gaze-based implicit elicitation of cognitive styles in real-time is feasible, which could be used by interactive systems to adapt to the users' cognitive needs and preferences, to better assist them, and improve their performance and experience.},
  file = {/Users/august/Zotero/storage/3U6H8BCX/Raptis et al. - 2017 - Using Eye Gaze Data and Visual Activities to Infer.pdf},
  isbn = {978-1-4503-4635-1},
  keywords = {eye-tracking,human cognitive styles,user study,visual decision-making tasks,visual search tasks},
  series = {{{UMAP}} '17}
}

@inproceedings{raptisUsingEyeTracking2016,
  title = {Using {{Eye Tracking}} to {{Identify Cognitive Differences}}: {{A Brief Literature Review}}},
  shorttitle = {Using {{Eye Tracking}} to {{Identify Cognitive Differences}}},
  booktitle = {Proceedings of the 20th {{Pan}}-{{Hellenic Conference}} on {{Informatics}}},
  author = {Raptis, George E. and Fidas, Christos A. and Avouris, Nikolaos M.},
  year = {2016},
  month = nov,
  pages = {1--6},
  publisher = {{ACM}},
  address = {{Patras Greece}},
  doi = {10.1145/3003733.3003762},
  abstract = {Being the windows to the soul, eyes reveal information about individuals' feelings, emotions and behaviour, affecting various cognitive tasks, such as focus of attention, spatial cognition and navigation, cognitive load, etc. With the increased use of computer systems, complex information is visualized and communicated through visual interfaces as a mean of information presentation to and processing by the users. However, people differ regarding the way they seek, retrieve, process, comprehend, organize and recall information, based on their individual perceptual characteristics, cognitive skills, abilities and styles. Therefore, the point and the motion of the eye gaze could reveal behavioural patterns related to individual cognitive differences; patterns that are extracted using eye tracking tools which quantify and provide compelling data regarding eye gaze movement. In this paper we review the current literature regarding the effect between the FD-I cognitive style of users in visual exploration and search activities and to correlate these with objective measures gathered through eye-tracking.},
  file = {/Users/august/Zotero/storage/WITRISTZ/Raptis et al. - 2016 - Using Eye Tracking to Identify Cognitive Differenc.pdf},
  isbn = {978-1-4503-4789-1},
  language = {en}
}

@inproceedings{ribeiroMLaaSMachineLearning2015,
  title = {{{MLaaS}}: {{Machine Learning}} as a {{Service}}},
  shorttitle = {{{MLaaS}}},
  booktitle = {2015 {{IEEE}} 14th {{International Conference}} on {{Machine Learning}} and {{Applications}} ({{ICMLA}})},
  author = {Ribeiro, Mauro and Grolinger, Katarina and Capretz, Miriam A.M.},
  year = {2015},
  month = dec,
  pages = {896--902},
  doi = {10.1109/ICMLA.2015.152},
  abstract = {The demand for knowledge extraction has been increasing. With the growing amount of data being generated by global data sources (e.g., social media and mobile apps) and the popularization of context-specific data (e.g., the Internet of Things), companies and researchers need to connect all these data and extract valuable information. Machine learning has been gaining much attention in data mining, leveraging the birth of new solutions. This paper proposes an architecture to create a flexible and scalable machine learning as a service. An open source solution was implemented and presented. As a case study, a forecast of electricity demand was generated using real-world sensor and weather data by running different algorithms at the same time.},
  file = {/Users/august/Zotero/storage/W3KI6LHN/Ribeiro et al. - 2015 - MLaaS Machine Learning as a Service.pdf;/Users/august/Zotero/storage/7RPHDYDF/7424435.html},
  keywords = {Adaptation models,Computer architecture,Data models,Machine learning algorithms,Machine Learning as a Service,Platform as a Service,Prediction,Prediction algorithms,Predictive models,Regression,Service Component Architecture,Service Oriented Architecture,Supervised Learning,Training}
}

@inproceedings{rogersGeneralizabilityDocumentFeatures2017,
  title = {Generalizability of {{Document Features}} for {{Identifying Rationale}}},
  booktitle = {Design {{Computing}} and {{Cognition}} '16},
  author = {Rogers, Benjamin and Justice, Connor and Mathur, Tanmay and Burge, Janet E.},
  editor = {Gero, John. S},
  year = {2017},
  pages = {633--651},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-44989-0_34},
  abstract = {One of the challenges in using statistical machine learning for text mining is coming up with the right set of text features. We have developed a system that uses genetic algorithms (GAs) to evaluate candidate feature sets to classify sentences in a document. We have applied this tool to find design rationale (the reasons behind design decisions) in two different datasets to evaluate our approach for finding rationale and to see how features might differ for the same classification target in different types of data. We used Chrome bug reports and transcripts of design sessions. We found that we were able to get results with less overfitting by using a smaller set of features common to the set optimized for each document type.},
  file = {/Users/august/Zotero/storage/33YKA6T9/Rogers et al. - 2017 - Generalizability of Document Features for Identify.pdf},
  isbn = {978-3-319-44989-0},
  keywords = {Information Gain,Linguistic Feature,Machine Learning Classifier,Sentence Length,Text Mining},
  language = {en}
}

@article{romanMachineLearningPipeline2021,
  title = {Machine Learning Pipeline for Battery State-of-Health Estimation},
  author = {Roman, Darius and Saxena, Saurabh and Robu, Valentin and Pecht, Michael and Flynn, David},
  year = {2021},
  month = apr,
  pages = {1--10},
  publisher = {{Nature Publishing Group}},
  issn = {2522-5839},
  doi = {10.1038/s42256-021-00312-3},
  abstract = {Lithium-ion batteries are ubiquitous in applications ranging from portable electronics to electric vehicles. Irrespective of the application, reliable real-time estimation of battery state of health (SOH) by on-board computers is crucial to the safe operation of the battery, ultimately safeguarding asset integrity. In this Article, we design and evaluate a machine learning pipeline for estimation of battery capacity fade\textemdash a metric of battery health\textemdash on 179 cells cycled under various conditions. The pipeline estimates battery SOH with an associated confidence interval by using two parametric and two non-parametric algorithms. Using segments of charge voltage and current curves, the pipeline engineers 30 features, performs automatic feature selection and calibrates the algorithms. When deployed on cells operated under the fast-charging protocol, the best model achieves a root-mean-squared error of 0.45\%. This work provides insights into the design of scalable data-driven models for battery SOH estimation, emphasizing the value of confidence bounds around the prediction. The pipeline methodology combines experimental data with machine learning modelling and could be applied to other critical components that require real-time estimation of SOH.},
  copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
  file = {/Users/august/Zotero/storage/PU4RA8HV/Roman et al. - 2021 - Machine learning pipeline for battery state-of-hea.pdf;/Users/august/Zotero/storage/DL97GDC5/s42256-021-00312-3.html},
  journal = {Nature Machine Intelligence},
  language = {en}
}

@article{rupprechtImprovingReproducibilityData2020,
  title = {Improving Reproducibility of Data Science Pipelines through Transparent Provenance Capture},
  author = {Rupprecht, Lukas and Davis, James C. and Arnold, Constantine and Gur, Yaniv and Bhagwat, Deepavali},
  year = {2020},
  month = aug,
  volume = {13},
  pages = {3354--3368},
  issn = {2150-8097},
  doi = {10.14778/3415478.3415556},
  abstract = {Data science has become prevalent in a large variety of domains. Inherent in its practice is an exploratory, probing, and fact finding journey, which consists of the assembly, adaptation, and execution of complex data science pipelines. The trustworthiness of the results of such pipelines rests entirely on their ability to be reproduced with fidelity, which is difficult if pipelines are not documented or recorded minutely and consistently. This difficulty has led to a reproducibility crisis and presents a major obstacle to the safe adoption of the pipeline results in production environments. The crisis can be resolved if the provenance for each data science pipeline is captured transparently as pipelines are executed. However, due to the complexity of modern data science pipelines, transparently capturing sufficient provenance to allow for reproducibility is challenging. As a result, most existing systems require users to augment their code or use specific tools to capture provenance, which hinders productivity and results in a lack of adoption. In this paper, we present Ursprung,1 a transparent provenance collection system designed for data science environments.2 The Ursprung philosophy is to capture provenance and build lineage by integrating with the execution environment to automatically track static and runtime configuration parameters of data science pipelines. Rather than requiring data scientists to make changes to their code, Ursprung records basic provenance information from system-level sources and combines it with provenance from application-level sources (e.g., log files, stdout), which can be accessed and recorded through a domain-specific language. In our evaluation, we show that Ursprung is able to capture sufficient provenance for a variety of use cases and only adds an overhead of up to 4\%.},
  file = {/Users/august/Zotero/storage/6AUJZTYD/Rupprecht et al. - 2020 - Improving reproducibility of data science pipeline.pdf},
  journal = {Proceedings of the VLDB Endowment},
  number = {12}
}

@article{saariGeneralizabilitySimplicityCriteria2011,
  title = {Generalizability and {{Simplicity}} as {{Criteria}} in {{Feature Selection}}: {{Application}} to {{Mood Classification}} in {{Music}}},
  shorttitle = {Generalizability and {{Simplicity}} as {{Criteria}} in {{Feature Selection}}},
  author = {Saari, P. and Eerola, T. and Lartillot, O.},
  year = {2011},
  month = aug,
  volume = {19},
  pages = {1802--1812},
  issn = {1558-7924},
  doi = {10.1109/TASL.2010.2101596},
  abstract = {Classification of musical audio signals according to expressed mood or emotion has evident applications to content-based music retrieval in large databases. Wrapper selection is a dimension reduction method that has been proposed for improving classification performance. However, the technique is prone to lead to overfitting of the training data, which decreases the generalizability of the obtained results. We claim that previous attempts to apply wrapper selection in the field of music information retrieval (MIR) have led to disputable conclusions about the used methods due to inadequate analysis frameworks, indicative of overfitting, and biased results. This paper presents a framework based on cross-indexing for obtaining realistic performance estimate of wrapper selection by taking into account the simplicity and generalizability of the classification models. The framework is applied on sets of film soundtrack excerpts that are consensually associated with particular basic emotions, comparing Naive Bayes, k-NN, and SVM classifiers using both forward selection (FS) and backward elimination (BE). K-NN with BE yields the most promising results - 56.5\% accuracy with only four features. The most useful feature subset for k-NN contains mode majorness and key clarity, combined with dynamical, rhythmical, and structural features.},
  file = {/Users/august/Zotero/storage/B6SMWPYH/5676183.html},
  journal = {IEEE Transactions on Audio, Speech, and Language Processing},
  keywords = {Accuracy,audio signal processing,backward elimination,Bayes methods,content-based music retrieval,cross-indexing,Cross-indexing,dimension reduction method,Emotion recognition,Feature extraction,feature selection,film soundtrack,forward selection,k-NN,Materials,MIR,Mood,mood classification,music,Music,music and emotion,music information retrieval,musical audio signal classification,musical features,naive Bayes,overfitting,Prediction algorithms,signal classification,support vector machines,SVM classifier,wrapper selection},
  number = {6}
}

@article{salminenMachineLearningApproach2019,
  title = {Machine Learning Approach to Auto-Tagging Online Content for Content Marketing Efficiency: {{A}} Comparative Analysis between Methods and Content Type},
  shorttitle = {Machine Learning Approach to Auto-Tagging Online Content for Content Marketing Efficiency},
  author = {Salminen, Joni and Yoganathan, Vignesh and Corporan, Juan and Jansen, Bernard J. and Jung, Soon-Gyo},
  year = {2019},
  month = aug,
  volume = {101},
  pages = {203--217},
  issn = {0148-2963},
  doi = {10.1016/j.jbusres.2019.04.018},
  abstract = {As complex data becomes the norm, greater understanding of machine learning (ML) applications is needed for content marketers. Unstructured data, scattered across platforms in multiple forms, impedes performance and user experience. Automated classification offers a solution to this. We compare three state-of-the-art ML techniques for multilabel classification - Random Forest, K-Nearest Neighbor, and Neural Network - to automatically tag and classify online news articles. Neural Network performs the best, yielding an F1 Score of 70\% and provides satisfactory cross-platform applicability on the same organisation's YouTube content. The developed model can automatically label 99.6\% of the unlabelled website and 96.1\% of the unlabelled YouTube content. Thus, we contribute to marketing literature via comparative evaluation of ML models for multilabel content classification, and cross-channel validation for a different type of content. Results suggest that organisations may optimise ML to auto-tag content across various platforms, opening avenues for aggregated analyses of content performance.},
  file = {/Users/august/Zotero/storage/F756SSAH/Salminen et al. - 2019 - Machine learning approach to auto-tagging online c.pdf;/Users/august/Zotero/storage/HSAPPN3B/S0148296319302607.html},
  journal = {Journal of Business Research},
  keywords = {Auto-tagging,Content marketing,Digital marketing,Machine learning,Neural network,Web content},
  language = {en}
}

@article{schwabMakingScientificComputations2000,
  title = {Making Scientific Computations Reproducible},
  author = {Schwab, M. and Karrenbach, N. and Claerbout, J.},
  year = {2000},
  month = nov,
  volume = {2},
  pages = {61--67},
  issn = {1558-366X},
  doi = {10.1109/5992.881708},
  abstract = {To verify a research paper's computational results, readers typically have to recreate them from scratch. ReDoc is a simple software filing system for authors that lets readers easily reproduce computational results using standardized rules and commands.},
  file = {/Users/august/Zotero/storage/LTACET79/Schwab et al. - 2000 - Making scientific computations reproducible.pdf;/Users/august/Zotero/storage/4JQ4ZK2E/881708.html},
  journal = {Computing in Science Engineering},
  keywords = {Computer interfaces,Documentation,Electronic publishing,Laboratories,Organizing,Reproducibility of results,Software maintenance,Software systems,Software testing,Technological innovation},
  number = {6}
}

@article{shaikhEndToEndMachineLearning2017,
  title = {An {{End}}-{{To}}-{{End Machine Learning Pipeline That Ensures Fairness Policies}}},
  author = {Shaikh, Samiulla and Vishwakarma, Harit and Mehta, Sameep and Varshney, Kush R. and Ramamurthy, Karthikeyan Natesan and Wei, Dennis},
  year = {2017},
  month = oct,
  abstract = {In consequential real-world applications, machine learning (ML) based systems are expected to provide fair and non-discriminatory decisions on candidates from groups defined by protected attributes such as gender and race. These expectations are set via policies or regulations governing data usage and decision criteria (sometimes explicitly calling out decisions by automated systems). Often, the data creator, the feature engineer, the author of the algorithm and the user of the results are different entities, making the task of ensuring fairness in an end-to-end ML pipeline challenging. Manually understanding the policies and ensuring fairness in opaque ML systems is time-consuming and error-prone, thus necessitating an end-to-end system that can: 1) understand policies written in natural language, 2) alert users to policy violations during data usage, and 3) log each activity performed using the data in an immutable storage so that policy compliance or violation can be proven later. We propose such a system to ensure that data owners and users are always in compliance with fairness policies.},
  archiveprefix = {arXiv},
  eprint = {1710.06876},
  eprinttype = {arxiv},
  file = {/Users/august/Zotero/storage/74HBIT5C/Shaikh et al. - 2017 - An End-To-End Machine Learning Pipeline That Ensur.pdf;/Users/august/Zotero/storage/9YN4DQRR/1710.html},
  journal = {arXiv:1710.06876 [cs]},
  keywords = {Computer Science - Computers and Society},
  note = {Comment: Presented at the Data For Good Exchange 2017},
  primaryclass = {cs}
}

@article{sharmaAssessingCognitivePerformance2020,
  title = {Assessing {{Cognitive Performance Using Physiological}} and {{Facial Features}}: {{Generalizing}} across {{Contexts}}},
  shorttitle = {Assessing {{Cognitive Performance Using Physiological}} and {{Facial Features}}},
  author = {Sharma, Kshitij and Niforatos, Evangelos and Giannakos, Michail and Kostakos, Vassilis},
  year = {2020},
  month = sep,
  volume = {4},
  pages = {95:1--95:41},
  doi = {10.1145/3411811},
  abstract = {Sensing and machine learning advances have enabled the unobtrusive measurement of physiological responses and facial expressions so as to estimate one's cognitive performance. This often boils down to mapping the states of the cognitive processes underpinning human cognition: physiological responses (e.g., heart rate) and facial expressions (e.g., frowning) often reflect the states of our cognitive processes. However, it remains unclear whether physiological responses and facial expressions used in one particular task (e.g., gaming) can reliably assess cognitive performance in another task (e.g., coding), because complex and diverse tasks often require varying levels and combinations of cognitive processes. In this paper, we measure the cross-task reliability of physiological and facial responses. Specifically, we assess cognitive performance based on physiological responses and facial expressions for 123 participants in 4 independent studies (3 studies for out-of-sampling training and testing, and 1 study for evaluation only): (1) a Pac-Man game, (2) an adaptive-assessment task, (3) a code-debugging task, and (4) a gaze-based game. We follow an ensemble learning approach after cross-training and cross-testing with all possible combinations of the 3 first datasets. We save the 4th dataset only for testing purposes, and we showcase how to engineer generalizable features that predict cognitive performance. Our results show that the extracted features do generalize, and can reliably predict cognitive performance across a diverse set of cognitive tasks that require different combinations of problem-solving, decision-making, and learning processes for their completion.},
  file = {/Users/august/Zotero/storage/PFRPWWCK/Sharma et al. - 2020 - Assessing Cognitive Performance Using Physiologica.pdf},
  journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  keywords = {Adaptive assessment,Cognitive performance,Debugging,Educational technology,Ensemble learning,Feature Generalizability,GARCH,Gaze-contingency,Learning Analytics,MMLA,Multimodal Learning Analytics,Skill-acquisition},
  number = {3}
}

@article{sharmaEyetrackingArtificialIntelligence2020,
  title = {Eye-Tracking and Artificial Intelligence to Enhance Motivation and Learning},
  author = {Sharma, Kshitij and Giannakos, Michail and Dillenbourg, Pierre},
  year = {2020},
  month = apr,
  volume = {7},
  pages = {13},
  issn = {2196-7091},
  doi = {10.1186/s40561-020-00122-x},
  abstract = {The interaction with the various learners in a Massive Open Online Course (MOOC) is often complex. Contemporary MOOC learning analytics relate with click-streams, keystrokes and other user-input variables. Such variables however, do not always capture users' learning and behavior (e.g., passive video watching). In this paper, we present a study with 40 students who watched a MOOC lecture while their eye-movements were being recorded. We then proposed a method to define stimuli-based gaze variables that can be used for any kind of stimulus. The proposed stimuli-based gaze variables indicate students' content-coverage (in space and time) and reading processes (area of interest based variables) and attention (i.e., with-me-ness), at the perceptual (following teacher's deictic acts) and conceptual levels (following teacher discourse). In our experiment, we identified a significant mediation effect of the content coverage, reading patterns and the two levels of with-me-ness on the relation between students' motivation and their learning performance. Such variables enable common measurements for the different kind of stimuli present in distinct MOOCs. Our long-term goal is to create student profiles based on their performance and learning strategy using stimuli-based gaze variables and to provide students gaze-aware feedback to improve overall learning process. One key ingredient in the process of achieving a high level of adaptation in providing gaze-aware feedback to the students is to use Artificial Intelligence (AI) algorithms for prediction of student performance from their behaviour. In this contribution, we also present a method combining state-of-the-art AI technique with the eye-tracking data to predict student performance. The results show that the student performance can be predicted with an error of less than 5\%.},
  file = {/Users/august/Zotero/storage/3Q5DN52Q/Sharma et al. - 2020 - Eye-tracking and artificial intelligence to enhanc.pdf;/Users/august/Zotero/storage/W397JKF6/s40561-020-00122-x.html},
  journal = {Smart Learning Environments},
  keywords = {Deep learning,Eye-tracking,Learning,Massive open online courses,MOOCs,Motivation,Multimodal analytics,Video based learning},
  number = {1}
}

@inproceedings{sharmaLookingLookingDual2015,
  title = {Looking {{AT}} versus {{Looking THROUGH}}: {{A Dual Eye}}-{{Tracking Study}} in {{MOOC Context}}},
  shorttitle = {Looking {{AT}} versus {{Looking THROUGH}}},
  booktitle = {{{CSCL}}},
  author = {Sharma, K. and Caballero, Daniela and Verma, Himanshu and Jermann, Patrick and Dillenbourg, P.},
  year = {2015},
  abstract = {We report the results from an eye-tracking study to show the differences in gaze patterns across the MOOC learners, while they watch a lecture individually as well as when they collaborate on an add-on activity. 98 university students took part in a study where they watched the MOOC video individually and later they collaboratively constructed a concept map. In both phases the gaze data was recorded. We compute two gaze measures: (1) with-me-ness, to quantify how much students follow the teacher during the video lecture, (2) gaze similarity, to quantify how much the pair looks at the same set of objects while collaborating. The analysis shows that both of the measures correlate significantly with the learning outcome. We argue that these results, conforming to our previous findings, indicate that the proposed gaze measures give a fairly accurate proxy to learners' engagement and performance.}
}

@article{sharmaMeasuringCausalityCollaborative2021,
  title = {Measuring Causality between Collaborative and Individual Gaze Metrics for Collaborative Problem-Solving with Intelligent Tutoring Systems},
  author = {Sharma, Kshitij and Olsen, Jennifer K. and Aleven, Vincent and Rummel, Nikol},
  year = {2021},
  volume = {37},
  pages = {51--68},
  issn = {1365-2729},
  doi = {10.1111/jcal.12467},
  abstract = {When students are working collaboratively and communicating verbally in a technology-enhanced environment, the system cannot track what collaboration is happening outside of the technology, making it difficult to fully assess the collaboration of the students and adapt accordingly. In this article, we propose using gaze measures as a proxy for cognitive processes to achieve collaboration awareness. Specifically, we use Granger causality to analyse the causal relationships between collaborative and individual gaze measures from students working on a fractions intelligent tutoring system and the influence that the students' dialogue, prior knowledge, or success has on these relationships. We found that collaborative gaze patterns drive the individual focus in the pairs with high posttest scores and when they are engaged in problem-solving dialogues but the opposite with low performing students. Our work adds to the literature by extending the correlational relationships between individual and collaborative gaze measures to causal relationships and suggests indicators that can be used within an adaptive system.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/jcal.12467},
  file = {/Users/august/Zotero/storage/PLKQVXHT/Sharma et al. - 2021 - Measuring causality between collaborative and indi.pdf;/Users/august/Zotero/storage/ZJQQYA7L/jcal.html},
  journal = {Journal of Computer Assisted Learning},
  keywords = {collaboration,collaborative learning,CSCL,dual eye-tracking,Granger causality,ITS},
  language = {en},
  number = {1}
}

@article{shojaeizadehDetectingTaskDemand2019,
  title = {Detecting Task Demand via an Eye Tracking Machine Learning System},
  author = {Shojaeizadeh, Mina and Djamasbi, Soussan and Paffenroth, Randy C. and Trapp, Andrew C.},
  year = {2019},
  month = jan,
  volume = {116},
  pages = {91--101},
  issn = {0167-9236},
  doi = {10.1016/j.dss.2018.10.012},
  abstract = {Computerized systems play a significant role in today's fast-paced digital economy. Because task demand is a major factor that influences how computerized systems are used to make decisions, identifying task demand automatically provides an opportunity for designing advanced decision support systems that can respond to user needs at a personalized level. A first step for designing such advanced decision tools is to investigate possibilities for developing automatic task load detectors. Grounded in decision making, eye tracking, and machine learning literature, we argue that task demand can be detected automatically, reliably, and unobtrusively using eye movements only. To investigate this possibility, we developed an eye tracking task load detection system and tested its effectiveness. Our results revealed that our task load detection system reliably predicted increased task demand from users' eye movement data. These results and their implications for research and practice are discussed.},
  file = {/Users/august/Zotero/storage/XSSUTKWT/Shojaeizadeh et al. - 2019 - Detecting task demand via an eye tracking machine .pdf;/Users/august/Zotero/storage/CV5AWDFS/S0167923618301696.html},
  journal = {Decision Support Systems},
  keywords = {Adaptive decision making,Cognitive effort,Eye tracking,Human computer interaction,Machine learning,Task demand},
  language = {en}
}

@inproceedings{steichenUseradaptiveInformationVisualization2013,
  title = {User-Adaptive Information Visualization: Using Eye Gaze Data to Infer Visualization Tasks and User Cognitive Abilities},
  shorttitle = {User-Adaptive Information Visualization},
  booktitle = {Proceedings of the 2013 International Conference on {{Intelligent}} User Interfaces},
  author = {Steichen, Ben and Carenini, Giuseppe and Conati, Cristina},
  year = {2013},
  month = mar,
  pages = {317--328},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2449396.2449439},
  abstract = {Information Visualization systems have traditionally followed a one-size-fits-all model, typically ignoring an individual user's needs, abilities and preferences. However, recent research has indicated that visualization performance could be improved by adapting aspects of the visualization to each individual user. To this end, this paper presents research aimed at supporting the design of novel user-adaptive visualization systems. In particular, we discuss results on using information on user eye gaze patterns while interacting with a given visualization to predict the user's visualization tasks, as well as user cognitive abilities including perceptual speed, visual working memory, and verbal working memory. We show that such predictions are significantly better than a baseline classifier even during the early stages of visualization usage. These findings are discussed in view of designing visualization systems that can adapt to each individual user in real-time.},
  file = {/Users/august/Zotero/storage/HPIBKG9W/Steichen et al. - 2013 - User-adaptive information visualization using eye.pdf},
  isbn = {978-1-4503-1965-2},
  keywords = {adaptation,adaptive information visualization,eye-tracking,machine learning},
  series = {{{IUI}} '13}
}

@article{stewartGeneralizabilityFaceBasedMind,
  title = {Generalizability of {{Face}}-{{Based Mind Wandering Detection Across Task Contexts}}},
  author = {Stewart, Angela and Bosch, Nigel and D'Mello, Sidney K},
  pages = {8},
  abstract = {We investigate generalizability of face-based detectors of mind wandering across task contexts. We leveraged data from two lab studies: one where 152 college students read a scientific text and another where 109 college students watched a narrative film. We automatically extracted facial expressions and body motion features, which were used to train supervised machine learning models on each dataset, as well as a concatenated dataset. We applied models from each task context (scientific text or narrative film) to the alternate context to study generalizability. We found that models trained on the narrative film dataset generalized to the scientific text dataset with no modifications, but the predicted mind wandering rate needed to be adjusted before models trained on the scientific text dataset would generalize to the narrative film dataset. Additionally, we analyzed generalizability of individual features and found that the lip tightener and jaw drop action units had the greatest potential to generalize across task contexts. We discuss findings and applications of our work to attention-aware learning technologies.},
  file = {/Users/august/Zotero/storage/SZTWPKBQ/Stewart et al. - Generalizability of Face-Based Mind Wandering Dete.pdf},
  language = {en}
}

@article{suttonPhysOnlineOpenSource2019,
  title = {{{PhysOnline}}: {{An Open Source Machine Learning Pipeline}} for {{Real}}-{{Time Analysis}} of {{Streaming Physiological Waveform}}},
  shorttitle = {{{PhysOnline}}},
  author = {Sutton, Jacob R. and Mahajan, Ruhi and Akbilgic, Oguz and Kamaleswaran, Rishikesan},
  year = {2019},
  month = jan,
  volume = {23},
  pages = {59--65},
  issn = {2168-2208},
  doi = {10.1109/JBHI.2018.2832610},
  abstract = {Real-time analysis of streaming physiological data to identify earlier abnormal conditions is an important aspect of precision medicine. However, open-source systems supporting this workflow are lacking. In this paper, we present PhysOnline, a pipeline built on the open-source Apache Spark platform to ingest streaming physiological data for online feature extraction and machine learning. We consider scalability factors for horizontal deployment to support growing analysis requirements. We further integrate real-time feature extraction, including pattern recognition methods as well as descriptive statistical components to identify temporal characteristics of waveform signals. These generated features are then used for machine learning and for real-time classification of abnormal conditions. As a case study, we present the online classification of electrocardiography recordings for screening Paroxysmal Atrial Fibrillation (PAF) and demonstrate that our pipeline can predict persons developing PAF at least 45 min. before an episode of that condition. This pipeline can be applied in domains where pattern matching, temporal abstractions, and morphological characteristics can be used for real-time classification of streaming time-series data.},
  file = {/Users/august/Zotero/storage/VCYHF3KS/Sutton et al. - 2019 - PhysOnline An Open Source Machine Learning Pipeli.pdf;/Users/august/Zotero/storage/L39F9XHK/8353460.html},
  journal = {IEEE Journal of Biomedical and Health Informatics},
  keywords = {ECG,Electrocardiography,Feature extraction,machine learning,Machine learning,online analysis,Pipelines,point of care,precision medicine,Real-time feature extraction,Real-time systems,scalable analysis,sensors,Sparks},
  number = {1}
}

@inproceedings{tokerPupillometryHeadDistance2017,
  title = {Pupillometry and {{Head Distance}} to the {{Screen}} to {{Predict Skill Acquisition During Information Visualization Tasks}}},
  booktitle = {Proceedings of the 22nd {{International Conference}} on {{Intelligent User Interfaces}}},
  author = {Toker, Dereck and Lall{\'e}, S{\'e}bastien and Conati, Cristina},
  year = {2017},
  month = mar,
  pages = {221--231},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3025171.3025187},
  abstract = {In this paper we investigate using a variety of behavioral measures collectible with an eye tracker to predict a user's skill acquisition phase while performing various information visualization tasks with bar graphs. Our long term goal is to use this information in real-time to create user-adaptive visualizations that can provide personalized support to facilitate visualization processing based on the user's predicted skill level. We show that leveraging two additional content-independent data sources, namely information on a user's pupil dilation and head distance to the screen, yields a significant improvement for predictive accuracies of skill acquisition compared to predictions made using content-dependent information related to user eye gaze attention patterns, as was done in previous work. We show that including features from both pupil dilation and head distance to the screen improve the ability to predict users' skill acquisition state, beating both the baseline and a model using only content-dependent gaze information.},
  file = {/Users/august/Zotero/storage/ZRC2QT4T/Toker et al. - 2017 - Pupillometry and Head Distance to the Screen to Pr.pdf},
  isbn = {978-1-4503-4348-0},
  keywords = {classification,distance to the screen,eye tracking,information visualization,pupil dilation,skill acquisition,user modeling},
  series = {{{IUI}} '17}
}

@inproceedings{turneyExploitingContextWhen1993,
  title = {Exploiting {{Context When Learning}} to {{Classify}}},
  booktitle = {Proceedings of the {{European Conference}} on {{Machine Learning}}},
  author = {Turney, Peter D.},
  year = {1993},
  month = apr,
  pages = {402--407},
  publisher = {{Springer-Verlag}},
  address = {{Berlin, Heidelberg}},
  isbn = {978-3-540-56602-1},
  series = {{{ECML}} '93}
}

@article{turneyIdentificationContextSensitiveFeatures2002,
  title = {The {{Identification}} of {{Context}}-{{Sensitive Features}}: {{A Formal Definition}} of {{Context}} for {{Concept Learning}}},
  shorttitle = {The {{Identification}} of {{Context}}-{{Sensitive Features}}},
  author = {Turney, Peter},
  year = {2002},
  month = dec,
  volume = {cs.LG/0212038},
  abstract = {A large body of research in machine learning is concerned with supervised learning from examples. The examples are typically represented as vectors in a multi-dimensional feature space (also known as attribute-value descriptions). A teacher partitions a set of training examples into a finite number of classes. The task of the learning algorithm is to induce a concept from the training examples. In this paper, we formally distinguish three types of features: primary, contextual, and irrelevant features. We also formally define what it means for one feature to be context-sensitive to another feature. Context-sensitive features complicate the task of the learner and potentially impair the learner's performance. Our formal definitions make it possible for a learner to automatically identify context-sensitive features. After context-sensitive features have been identified, there are several strategies that the learner can employ for managing the features; however, a disc...},
  file = {/Users/august/Zotero/storage/6TLPHGER/Turney - 2002 - The Identification of Context-Sensitive Features .pdf},
  journal = {CoRR}
}

@inproceedings{turneyRobustClassificationContextsensitive1993,
  title = {Robust Classification with Context-Sensitive Features},
  booktitle = {Proceedings of the 6th International Conference on {{Industrial}} and Engineering Applications of Artificial Intelligence and Expert Systems},
  author = {Turney, P. D.},
  year = {1993},
  month = jun,
  pages = {268--276},
  publisher = {{Gordon \& Breach Science Publishers}},
  address = {{Edinburgh, Scotland}},
  isbn = {978-2-88124-604-3},
  series = {{{IEA}}/{{AIE}}'93}
}

@inproceedings{vaillancourtReproduciblePortableWorkflows2020a,
  title = {Reproducible and {{Portable Workflows}} for {{Scientific Computing}} and {{HPC}} in the {{Cloud}}},
  booktitle = {Practice and {{Experience}} in {{Advanced Research Computing}}},
  author = {Vaillancourt, Peter and Wineholt, Bennett and Barker, Brandon and Deliyannis, Plato and Zheng, Jackie and Suresh, Akshay and Brazier, Adam and Knepper, Rich and Wolski, Rich},
  year = {2020},
  month = jul,
  pages = {311--320},
  publisher = {{ACM}},
  address = {{Portland OR USA}},
  doi = {10.1145/3311790.3396659},
  file = {/Users/august/Zotero/storage/QFZNJYFH/Vaillancourt et al. - 2020 - Reproducible and Portable Workflows for Scientific.pdf},
  isbn = {978-1-4503-6689-2},
  language = {en}
}

@article{weintraubCognitionAssessmentUsing2013,
  title = {Cognition Assessment Using the {{NIH Toolbox}}},
  author = {Weintraub, S. and Dikmen, S. S. and Heaton, R. K. and Tulsky, D. S. and Zelazo, P. D. and Bauer, P. J. and Carlozzi, N. E. and Slotkin, J. and Blitz, D. and {Wallner-Allen}, K. and Fox, N. A. and Beaumont, J. L. and Mungas, D. and Nowinski, C. J. and Richler, J. and Deocampo, J. A. and Anderson, J. E. and Manly, J. J. and Borosh, B. and Havlik, R. and Conway, K. and Edwards, E. and Freund, L. and King, J. W. and Moy, C. and Witt, E. and Gershon, R. C.},
  year = {2013},
  month = mar,
  volume = {80},
  pages = {S54-S64},
  issn = {0028-3878, 1526-632X},
  doi = {10.1212/WNL.0b013e3182872ded},
  file = {/Users/august/Zotero/storage/M3FV5HA4/Weintraub et al. - 2013 - Cognition assessment using the NIH Toolbox.pdf},
  journal = {Neurology},
  language = {en},
  number = {Issue 11, Supplement 3}
}

@article{wisslerSpearmanCorrelationFormula1905,
  title = {The {{Spearman Correlation Formula}}},
  author = {Wissler, Clark},
  year = {1905},
  volume = {22},
  pages = {309--311},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  journal = {Science},
  number = {558}
}

@book{zhangTuC4DriverCognitive,
  title = {{{TuC4}}.1 {{Driver Cognitive Workload Estimation}}: {{A Data}}-Driven {{Perspective}}},
  shorttitle = {{{TuC4}}.1 {{Driver Cognitive Workload Estimation}}},
  author = {Zhang, Yilu and Owechko, Yuri and Zhang, Jing},
  abstract = {Abstract \textemdash{} Driver workload estimation (DWE) refers to the activities of monitoring the driver and the driving environment in real-time and acquiring the knowledge of driver's workload continuously. With this knowledge of driver's workload, the in-vehicle information systems (IVIS) can provide information when the driver has the spare capacity to receive and comprehend it, which is both effective and efficient. However, after years of study, it is still difficult to build a robust DWE system. In this paper, we analyze the difficulties facing the existing methodology of developing DWE systems and propose a machine-learning-based DWE development process. Some preliminary but promising results are reported using a popular machine-learning method, decision tree. I.},
  file = {/Users/august/Zotero/storage/NTPLC3PB/Zhang et al. - TuC4.1 Driver Cognitive Workload Estimation A Dat.pdf;/Users/august/Zotero/storage/MD2RQX25/download.html}
}


